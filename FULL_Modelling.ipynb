{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da56602c",
      "metadata": {},
      "source": [
        "# FULL_Modelling — M4–M7 Spatial Pipeline \n",
        "#### Run matrix: 3 exposures × 2 samples × 2 outcomes = 12 runs per model block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "69705a55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROOT: /Users/athamawardi/Desktop/Research-Projects/PSE_Pertamina\n",
            "COAST exists: True\n",
            "ALL exists: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "# IV / OLS\n",
        "import statsmodels.api as sm\n",
        "from linearmodels.iv import IV2SLS\n",
        "# OLSResults unused; sm.OLS().fit() used for SLX/SDM first stage\n",
        "\n",
        "# Spatial\n",
        "import libpysal\n",
        "from libpysal.weights import KNN\n",
        "from libpysal.weights.spatial_lag import lag_spatial\n",
        "from esda import Moran, Moran_Local\n",
        "import spreg\n",
        "\n",
        "# Geo / viz\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths (match Stata ROOT)\n",
        "ROOT = os.getcwd()\n",
        "if not os.path.exists(os.path.join(ROOT, \"Output\")):\n",
        "    ROOT = os.path.dirname(ROOT)\n",
        "\n",
        "PATH_COAST = os.path.join(ROOT, \"Output\", \"tsls\",  \"first_iv2sls_pesisir\", \"podes_vill_spbun_pca_iv.dta\")\n",
        "PATH_ALL   = os.path.join(ROOT, \"Output\", \"tsls\", \"first_iv2sls\", \"podes_vill_spbun_pca_iv.dta\")\n",
        "PATH_TSLS  = os.path.join(ROOT, \"Output\", \"tsls\", \"village_values\")\n",
        "BASEMAP_PATH = os.path.join(ROOT, \"Survey_Map\", \"id.json\")\n",
        "# Load basemap as GeoDataFrame so it can be plotted as a layer (fix: map layer on basemap)\n",
        "BASEMAP = gpd.read_file(BASEMAP_PATH) if os.path.exists(BASEMAP_PATH) else None\n",
        "\n",
        "OUT_DIRS = [\n",
        "    \"Output\", \"Output/tsls\",\n",
        "    \"Output/tsls/tables\", \"Output/tsls/figures\", \"Output/tsls/maps\",\n",
        "    \"Output/models\", \"Output/logs\",\n",
        "]\n",
        "for d in OUT_DIRS:\n",
        "    os.makedirs(os.path.join(ROOT, d), exist_ok=True)\n",
        "\n",
        "def out_path(*parts):\n",
        "    return os.path.join(ROOT, \"Output\", \"tsls\", *parts)\n",
        "\n",
        "print(\"ROOT:\", ROOT)\n",
        "print(\"COAST exists:\", os.path.exists(PATH_COAST))\n",
        "print(\"ALL exists:\", os.path.exists(PATH_ALL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "93870c02",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Global config (single source of truth) ---\n",
        "SAMPLES   = [\"COAST\", \"ALL\"]\n",
        "EXPOSURES = [\"A_v_log\", \"Ker5_w1\", \"Ker10_w1\"]\n",
        "OUTCOMES  = [\"lnpov_z\", \"Wbasic_z\"]\n",
        "\n",
        "FE_KEY    = \"kab\"\n",
        "CLUSTER_KEY = \"kab\"  # cluster-robust SE use FE_KEY (kab) in sm.OLS\n",
        "INSTRUMENTS = [\"Z_pel\", \"Z_tbbm\", \"Z_tpi\"]\n",
        "BASELINE_SPEC = \"IVH_UTIL_NB\"  # matches spec in village_values CSVs (was IVH_BASE — not present in data)\n",
        "W_TYPE = \"knn\"  # informational; build_W uses K_NEIGHBORS and W_TRANSFORM\n",
        "K_NEIGHBORS = 8\n",
        "W_TRANSFORM = \"R\"\n",
        "\n",
        "# Categorical controls (Stata X_S_base_cat; use raw names; _c if present in data)\n",
        "X_CAT_NAMES = [\"r308b1d\", \"r308b1e\", \"r309a\", \"r309b\", \"r309d\", \"r309e\", \"r310\", \"r403a\", \"r403c1\", \"r403c2\"]\n",
        "# PCA patterns: we'll select from dataframe (r509c dropped per plan)\n",
        "X_PCA_PATTERNS = [\"r701\", \"r711\"]  # cols like r701*_b, r711*_b; r509c* excluded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "fe249819",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X columns (47): ['r308b1d', 'r308b1e', 'r309a', 'r309b', 'r309d', 'r309e', 'r310', 'r403a', 'r403c1', 'r403c2', 'r701ak3_b', 'r701ak4_b', 'r701bk3_b', 'r701bk4_b', 'r701ck4_b'] ...\n",
            "r509c excluded from X (SDM and all models use X_COLS).\n",
            "COAST rows: 12968 | ALL rows: 84276\n"
          ]
        }
      ],
      "source": [
        "# --- Load analysis datasets and build control set X ---\n",
        "def load_analysis_data():\n",
        "    coast = pd.read_stata(PATH_COAST)\n",
        "    all_df = pd.read_stata(PATH_ALL)\n",
        "    # Standardize types\n",
        "    for df in [coast, all_df]:\n",
        "        if \"iddesa\" in df.columns:\n",
        "            df[\"iddesa\"] = df[\"iddesa\"].astype(str).str.strip()\n",
        "        # Keep kab as-is (often category in .dta); do not convert to numeric (loses all rows)\n",
        "        # if \"kab\" in df.columns: df[\"kab\"] = pd.to_numeric(...)\n",
        "        for c in [\"lat_v\", \"lon_v\"]:\n",
        "            if c in df.columns:\n",
        "                df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return {\"COAST\": coast, \"ALL\": all_df}\n",
        "\n",
        "def build_X(df):\n",
        "    \"\"\"Build X = X_CAT + X_PCA from available columns. Stata-aligned.\"\"\"\n",
        "    cat = [c for c in X_CAT_NAMES if c in df.columns]\n",
        "    pca = [c for c in df.columns if c.endswith(\"_b\") and any(c.startswith(p) for p in X_PCA_PATTERNS)]\n",
        "    return cat + sorted(pca)\n",
        "\n",
        "DATASETS = load_analysis_data()\n",
        "# X_COLS: use only columns present in BOTH COAST and ALL (r509c dropped — not in X_PCA_PATTERNS)\n",
        "x_all = build_X(DATASETS[\"ALL\"])\n",
        "X_COLS = [c for c in x_all if c in DATASETS[\"COAST\"].columns]\n",
        "print(\"X columns (%d):\" % len(X_COLS), X_COLS[:15], \"...\" if len(X_COLS) > 15 else \"\")\n",
        "print(\"r509c excluded from X (SDM and all models use X_COLS).\")\n",
        "print(\"COAST rows:\", len(DATASETS[\"COAST\"]), \"| ALL rows:\", len(DATASETS[\"ALL\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "c4572992",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded baseline files: [('A_v_log', 'v1'), ('A_v_log', 'v2'), ('Ker5_w1', 'v1'), ('Ker5_w1', 'v2'), ('Ker10_w1', 'v1'), ('Ker10_w1', 'v2')]\n"
          ]
        }
      ],
      "source": [
        "# --- Load Stata baseline village_values for M4 residual Moran ---\n",
        "# Files: village_values_long_v1/v2 (A_v_log), Ker5_*, Ker10_*\n",
        "def load_baseline_residuals():\n",
        "    out = {}\n",
        "    # A_v_log\n",
        "    for v in [\"v1\", \"v2\"]:\n",
        "        p = os.path.join(PATH_TSLS, f\"village_values_long_{v}.csv\")\n",
        "        if os.path.exists(p):\n",
        "            df = pd.read_csv(p)\n",
        "            df[\"iddesa\"] = df[\"iddesa\"].astype(str).str.strip()\n",
        "            out[(\"A_v_log\", v)] = df\n",
        "    # Ker5\n",
        "    for v in [\"v1\", \"v2\"]:\n",
        "        p = os.path.join(PATH_TSLS, f\"Ker5_village_values_long_{v}.csv\")\n",
        "        if os.path.exists(p):\n",
        "            df = pd.read_csv(p)\n",
        "            df[\"iddesa\"] = df[\"iddesa\"].astype(str).str.strip()\n",
        "            out[(\"Ker5_w1\", v)] = df\n",
        "    # Ker10\n",
        "    for v in [\"v1\", \"v2\"]:\n",
        "        p = os.path.join(PATH_TSLS, f\"Ker10_village_values_long_{v}.csv\")\n",
        "        if os.path.exists(p):\n",
        "            df = pd.read_csv(p)\n",
        "            df[\"iddesa\"] = df[\"iddesa\"].astype(str).str.strip()\n",
        "            out[(\"Ker10_w1\", v)] = df\n",
        "    return out\n",
        "\n",
        "BASELINE_VALUES = load_baseline_residuals()\n",
        "print(\"Loaded baseline files:\", list(BASELINE_VALUES.keys()))\n",
        "# Use v1 for baseline uhat; filter by sample, outcome, spec\n",
        "def get_baseline_uhat(exposure, sample, outcome, spec=BASELINE_SPEC):\n",
        "    key = (exposure, \"v1\")\n",
        "    if key not in BASELINE_VALUES:\n",
        "        return None\n",
        "    df = BASELINE_VALUES[key]\n",
        "    m = (df[\"sample\"] == sample) & (df[\"outcome\"] == outcome) & (df[\"spec\"] == spec)\n",
        "    out = df.loc[m, [\"iddesa\", \"uhat\", \"W_hat\"]].copy()\n",
        "    if len(out) == 0:\n",
        "        m2 = (df[\"sample\"] == sample) & (df[\"outcome\"] == outcome)\n",
        "        if m2.any():\n",
        "            out = df.loc[m2, [\"iddesa\", \"uhat\", \"W_hat\"]].drop_duplicates(subset=[\"iddesa\"])\n",
        "    return out if len(out) > 0 else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "c0de051a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Run dataframe: complete cases per (sample, exposure, outcome) ---\n",
        "def build_run_df(sample, exposure, outcome):\n",
        "    df = DATASETS[sample].copy()\n",
        "    y = outcome\n",
        "    A = exposure\n",
        "    req = [\"iddesa\", FE_KEY, \"lat_v\", \"lon_v\", y, A] + X_COLS + INSTRUMENTS\n",
        "    missing = [c for c in req if c not in df.columns]\n",
        "    if missing:\n",
        "        return None, {\"error\": \"missing_cols\", \"cols\": missing}\n",
        "    run = df[req].dropna(how=\"any\").reset_index(drop=True)\n",
        "    run = run.rename(columns={y: \"y\", A: \"A\"})\n",
        "    # Merge baseline uhat if available\n",
        "    uhat_df = get_baseline_uhat(exposure, sample, outcome)\n",
        "    if uhat_df is not None and len(uhat_df) > 0:\n",
        "        run = run.merge(uhat_df[[\"iddesa\", \"uhat\", \"W_hat\"]], on=\"iddesa\", how=\"left\")\n",
        "    else:\n",
        "        run[\"uhat\"] = np.nan\n",
        "        run[\"W_hat\"] = np.nan\n",
        "    manifest = {\n",
        "        \"sample\": sample, \"exposure\": exposure, \"outcome\": outcome,\n",
        "        \"N_raw\": len(df), \"N_used\": len(run),\n",
        "    }\n",
        "    return run, manifest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "bd06cd0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Spatial weights W (kNN, row-standardized) per sample ---\n",
        "def build_W(df):\n",
        "    \"\"\"df must have lat_v, lon_v; drop missing coords and duplicates for W.\"\"\"\n",
        "    g = df[[\"lat_v\", \"lon_v\"]].dropna(how=\"any\")\n",
        "    g = g.drop_duplicates()\n",
        "    coords = g[[\"lon_v\", \"lat_v\"]].values\n",
        "    W = KNN.from_array(coords, k=min(K_NEIGHBORS, len(coords) - 1))\n",
        "    W.transform = W_TRANSFORM\n",
        "    return W, g.index if hasattr(g, \"index\") else np.arange(len(g))\n",
        "\n",
        "# Build W per sample (reserved; run-level W uses build_W_for_run below)\n",
        "W_by_sample = {}\n",
        "for sample in SAMPLES:\n",
        "    df = DATASETS[sample]\n",
        "    g = df[[\"lat_v\", \"lon_v\"]].dropna(how=\"any\").drop_duplicates()\n",
        "    if len(g) < 2:\n",
        "        W_by_sample[sample] = None\n",
        "        continue\n",
        "    coords = df.loc[g.index][[\"lon_v\", \"lat_v\"]].values\n",
        "    W = KNN.from_array(coords, k=min(K_NEIGHBORS, len(coords) - 1))\n",
        "    W.transform = W_TRANSFORM\n",
        "    W_by_sample[sample] = (W, g.index.tolist())\n",
        "\n",
        "# For each run we need W aligned to run_df row order: rebuild W on run_df coords\n",
        "def build_W_for_run(run_df):\n",
        "    coords = run_df[[\"lon_v\", \"lat_v\"]].values\n",
        "    # Add tiny jitter to break ties from duplicate coordinates (prevents zero-distance KNN distortion)\n",
        "    rng = np.random.RandomState(42)\n",
        "    jitter = rng.normal(0, 1e-8, coords.shape)\n",
        "    coords = coords + jitter\n",
        "    k = min(K_NEIGHBORS, len(coords) - 1)\n",
        "    if k < 1:\n",
        "        return None\n",
        "    W = KNN.from_array(coords, k=k)\n",
        "    W.transform = W_TRANSFORM\n",
        "    return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "8598c849",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iddesa</th>\n",
              "      <th>nama_prov</th>\n",
              "      <th>nama_kab</th>\n",
              "      <th>nama_kec</th>\n",
              "      <th>nama_desa</th>\n",
              "      <th>r604a</th>\n",
              "      <th>r604b</th>\n",
              "      <th>r604c</th>\n",
              "      <th>r604d</th>\n",
              "      <th>r604e</th>\n",
              "      <th>...</th>\n",
              "      <th>A_v_inv</th>\n",
              "      <th>D_pel_iv</th>\n",
              "      <th>D_tbbm_iv</th>\n",
              "      <th>D_tpi_iv</th>\n",
              "      <th>Z_pel</th>\n",
              "      <th>Z_tbbm</th>\n",
              "      <th>Z_tpi</th>\n",
              "      <th>sd_Z_pel</th>\n",
              "      <th>sd_Z_tbbm</th>\n",
              "      <th>sd_Z_tpi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1101010001</td>\n",
              "      <td>ACEH</td>\n",
              "      <td>SIMEULUE</td>\n",
              "      <td>TEUPAH SELATAN</td>\n",
              "      <td>LATIUNG</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>18.700657</td>\n",
              "      <td>266.123706</td>\n",
              "      <td>94.590363</td>\n",
              "      <td>-2.980652</td>\n",
              "      <td>-5.587712</td>\n",
              "      <td>-4.560072</td>\n",
              "      <td>0.898514</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>0.757342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1101010002</td>\n",
              "      <td>ACEH</td>\n",
              "      <td>SIMEULUE</td>\n",
              "      <td>TEUPAH SELATAN</td>\n",
              "      <td>LABUHAN BAJAU</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007995</td>\n",
              "      <td>18.891550</td>\n",
              "      <td>261.118702</td>\n",
              "      <td>96.087853</td>\n",
              "      <td>-2.990295</td>\n",
              "      <td>-5.568797</td>\n",
              "      <td>-4.575616</td>\n",
              "      <td>0.898514</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>0.757342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101010003</td>\n",
              "      <td>ACEH</td>\n",
              "      <td>SIMEULUE</td>\n",
              "      <td>TEUPAH SELATAN</td>\n",
              "      <td>SUAK LAMATAN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007276</td>\n",
              "      <td>17.116508</td>\n",
              "      <td>275.192802</td>\n",
              "      <td>87.756199</td>\n",
              "      <td>-2.896824</td>\n",
              "      <td>-5.621099</td>\n",
              "      <td>-4.485893</td>\n",
              "      <td>0.898514</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>0.757342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1101010004</td>\n",
              "      <td>ACEH</td>\n",
              "      <td>SIMEULUE</td>\n",
              "      <td>TEUPAH SELATAN</td>\n",
              "      <td>ANA AO</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008168</td>\n",
              "      <td>12.603267</td>\n",
              "      <td>260.692994</td>\n",
              "      <td>90.080357</td>\n",
              "      <td>-2.610310</td>\n",
              "      <td>-5.567172</td>\n",
              "      <td>-4.511742</td>\n",
              "      <td>0.898514</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>0.757342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1101010005</td>\n",
              "      <td>ACEH</td>\n",
              "      <td>SIMEULUE</td>\n",
              "      <td>TEUPAH SELATAN</td>\n",
              "      <td>LATALING</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008221</td>\n",
              "      <td>11.319306</td>\n",
              "      <td>260.404786</td>\n",
              "      <td>88.743123</td>\n",
              "      <td>-2.511168</td>\n",
              "      <td>-5.566070</td>\n",
              "      <td>-4.496951</td>\n",
              "      <td>0.898514</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>0.757342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 497 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       iddesa nama_prov  nama_kab        nama_kec      nama_desa  r604a  \\\n",
              "0  1101010001      ACEH  SIMEULUE  TEUPAH SELATAN        LATIUNG      2   \n",
              "1  1101010002      ACEH  SIMEULUE  TEUPAH SELATAN  LABUHAN BAJAU      2   \n",
              "2  1101010003      ACEH  SIMEULUE  TEUPAH SELATAN   SUAK LAMATAN      2   \n",
              "3  1101010004      ACEH  SIMEULUE  TEUPAH SELATAN         ANA AO      2   \n",
              "4  1101010005      ACEH  SIMEULUE  TEUPAH SELATAN       LATALING      2   \n",
              "\n",
              "   r604b  r604c  r604d  r604e  ...   A_v_inv   D_pel_iv   D_tbbm_iv  \\\n",
              "0      2      1      1      1  ...  0.007692  18.700657  266.123706   \n",
              "1      2      2      2      2  ...  0.007995  18.891550  261.118702   \n",
              "2      2      2      2      2  ...  0.007276  17.116508  275.192802   \n",
              "3      2      2      2      2  ...  0.008168  12.603267  260.692994   \n",
              "4      2      2      2      2  ...  0.008221  11.319306  260.404786   \n",
              "\n",
              "    D_tpi_iv     Z_pel    Z_tbbm     Z_tpi  sd_Z_pel  sd_Z_tbbm  sd_Z_tpi  \n",
              "0  94.590363 -2.980652 -5.587712 -4.560072  0.898514   0.056373  0.757342  \n",
              "1  96.087853 -2.990295 -5.568797 -4.575616  0.898514   0.056373  0.757342  \n",
              "2  87.756199 -2.896824 -5.621099 -4.485893  0.898514   0.056373  0.757342  \n",
              "3  90.080357 -2.610310 -5.567172 -4.511742  0.898514   0.056373  0.757342  \n",
              "4  88.743123 -2.511168 -5.566070 -4.496951  0.898514   0.056373  0.757342  \n",
              "\n",
              "[5 rows x 497 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview pesisir (COAST) data\n",
        "DATASETS[\"COAST\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d2ba68",
      "metadata": {},
      "source": [
        "## M4 — Diagnostic spatial autocorrelation (Moran's I on outcome and baseline residuals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "2d8d3e44",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sample   outcome  exposure         target   moran_i  p_value     z_score\n",
            "0   COAST   lnpov_z         —              y  0.599305    0.001  141.885489\n",
            "1   COAST  Wbasic_z         —              y  0.838022    0.001  196.673818\n",
            "2     ALL   lnpov_z         —              y  0.655732    0.001  410.885337\n",
            "3     ALL  Wbasic_z         —              y  0.862522    0.001  520.444103\n",
            "4   COAST   lnpov_z   A_v_log  uhat_baseline  0.198883    0.001   48.563574\n",
            "5   COAST  Wbasic_z   A_v_log  uhat_baseline  0.214338    0.001   49.982059\n",
            "6   COAST   lnpov_z   Ker5_w1  uhat_baseline  0.217904    0.001   52.884868\n",
            "7   COAST  Wbasic_z   Ker5_w1  uhat_baseline  0.227698    0.001   53.161837\n",
            "8   COAST   lnpov_z  Ker10_w1  uhat_baseline  0.221004    0.001   51.456239\n",
            "9   COAST  Wbasic_z  Ker10_w1  uhat_baseline  0.235327    0.001   54.143538\n",
            "10    ALL   lnpov_z   A_v_log  uhat_baseline  0.217244    0.001  133.880503\n",
            "11    ALL  Wbasic_z   A_v_log  uhat_baseline  0.268066    0.001  163.302409\n",
            "12    ALL   lnpov_z   Ker5_w1  uhat_baseline  0.231953    0.001  140.460162\n",
            "13    ALL  Wbasic_z   Ker5_w1  uhat_baseline  0.280266    0.001  174.150653\n",
            "14    ALL   lnpov_z  Ker10_w1  uhat_baseline  0.231497    0.001  136.498453\n",
            "15    ALL  Wbasic_z  Ker10_w1  uhat_baseline  0.281100    0.001  173.580358\n"
          ]
        }
      ],
      "source": [
        "# M4.1 Moran's I on outcome (per sample × outcome)\n",
        "# M4.2 Moran's I on baseline residuals (per sample × exposure × outcome)\n",
        "moran_rows = []\n",
        "permutations = 999\n",
        "\n",
        "for sample in SAMPLES:\n",
        "    df = DATASETS[sample]\n",
        "    for outcome in OUTCOMES:\n",
        "        ycol = outcome\n",
        "        if ycol not in df.columns:\n",
        "            continue\n",
        "        run, _ = build_run_df(sample, EXPOSURES[0], outcome)  # any exposure for y-only\n",
        "        if run is None or len(run) < 10:\n",
        "            continue\n",
        "        W = build_W_for_run(run)\n",
        "        if W is None:\n",
        "            continue\n",
        "        y = run[\"y\"].values\n",
        "        mi = Moran(y, W, permutations=permutations)\n",
        "        moran_rows.append({\n",
        "            \"sample\": sample, \"outcome\": outcome, \"exposure\": \"—\",\n",
        "            \"target\": \"y\", \"moran_i\": mi.I, \"p_value\": mi.p_sim, \"z_score\": getattr(mi, \"z_sim\", np.nan),\n",
        "        })\n",
        "\n",
        "for sample in SAMPLES:\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            run, _ = build_run_df(sample, exposure, outcome)\n",
        "            if run is None or run[\"uhat\"].notna().sum() < 10:\n",
        "                continue\n",
        "            run = run.dropna(subset=[\"uhat\"])\n",
        "            W = build_W_for_run(run)\n",
        "            if W is None:\n",
        "                continue\n",
        "            u = run[\"uhat\"].values\n",
        "            mi = Moran(u, W, permutations=permutations)\n",
        "            moran_rows.append({\n",
        "                \"sample\": sample, \"outcome\": outcome, \"exposure\": exposure,\n",
        "                \"target\": \"uhat_baseline\", \"moran_i\": mi.I, \"p_value\": mi.p_sim, \"z_score\": getattr(mi, \"z_sim\", np.nan),\n",
        "            })\n",
        "\n",
        "moran_df = pd.DataFrame(moran_rows)\n",
        "moran_df.to_csv(out_path(\"tables\", \"moran_results.csv\"), index=False)\n",
        "print(moran_df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7918da4b",
      "metadata": {},
      "source": [
        "## M5 — SLX (Spatial Lag of X): y = β·A + θ·(W·A) + Γ·X + ε (FE: demean by kab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0fd7e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SLX done. Coefficients count: 144\n"
          ]
        }
      ],
      "source": [
        "# M5: SLX with FE (demean by kab), cluster-robust SE\n",
        "def demean_by(df, key, cols):\n",
        "    out = df.copy()\n",
        "    for c in cols:\n",
        "        if c in out.columns and pd.api.types.is_numeric_dtype(out[c]):\n",
        "            out[c] = out[c] - out.groupby(key, observed=True)[c].transform(\"mean\")\n",
        "    return out\n",
        "\n",
        "def run_slx(run_df, W, X_cols):\n",
        "    \"\"\"SLX on demeaned y, A, WA, X. OLS with cluster-robust SE (kab).\"\"\"\n",
        "    run = run_df.copy()\n",
        "    run[\"WA\"] = lag_spatial(W, run[\"A\"].values)\n",
        "    to_demean = [\"y\", \"A\", \"WA\"] + [c for c in X_cols if c in run.columns]\n",
        "    run = demean_by(run, FE_KEY, to_demean)\n",
        "    exog = [\"A\", \"WA\"] + [c for c in X_cols if c in run.columns and run[c].notna().all() and pd.api.types.is_numeric_dtype(run[c])]\n",
        "    X = sm.add_constant(run[exog].astype(np.float64), has_constant=\"add\")\n",
        "    y = run[\"y\"].astype(np.float64)\n",
        "    groups = run[FE_KEY].astype(str) if run[FE_KEY].dtype.name == \"category\" else run[FE_KEY]\n",
        "    mod = sm.OLS(y, X).fit(cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
        "    resid = run[\"y\"].values - mod.predict(X)\n",
        "    return mod, resid, exog\n",
        "\n",
        "slx_rows = []\n",
        "slx_moran_rows = []\n",
        "for sample in SAMPLES:\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            run, _ = build_run_df(sample, exposure, outcome)\n",
        "            if run is None or len(run) < 20:\n",
        "                continue\n",
        "            W = build_W_for_run(run)\n",
        "            if W is None:\n",
        "                continue\n",
        "            try:\n",
        "                mod, resid, exog = run_slx(run, W, X_COLS)\n",
        "                for p in exog:\n",
        "                    if p in mod.params.index:\n",
        "                        slx_rows.append({\n",
        "                            \"sample\": sample, \"exposure\": exposure, \"outcome\": outcome,\n",
        "                            \"term\": p, \"coef\": mod.params[p], \"se\": mod.bse[p], \"pvalue\": mod.pvalues[p],\n",
        "                        })\n",
        "                # Post-fit Moran on SLX residuals\n",
        "                mi = Moran(resid, W, permutations=999)\n",
        "                slx_moran_rows.append({\n",
        "                    \"sample\": sample, \"exposure\": exposure, \"outcome\": outcome,\n",
        "                    \"moran_i\": mi.I, \"p_value\": mi.p_sim,\n",
        "                })\n",
        "            except Exception as e:\n",
        "                slx_rows.append({\"sample\": sample, \"exposure\": exposure, \"outcome\": outcome, \"term\": \"error\", \"coef\": np.nan, \"se\": np.nan, \"pvalue\": np.nan})\n",
        "\n",
        "pd.DataFrame(slx_rows).to_csv(out_path(\"tables\", \"slx_results_long.csv\"), index=False)\n",
        "pd.DataFrame(slx_moran_rows).to_csv(out_path(\"tables\", \"slx_post_moran.csv\"), index=False)\n",
        "print(\"SLX done. Coefficients count:\", len(slx_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a985f3ed",
      "metadata": {},
      "source": [
        "## M6 — SDM (Spatial Durbin) with IV-style exposure: first stage A_hat, then spatial lag model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c6d9050",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDM done. Coefficients: 156\n"
          ]
        }
      ],
      "source": [
        "# M6.1 First stage: A_tilde ~ Z_tilde + X_tilde (by kab), get A_hat\n",
        "# M6.2 Build WA_hat, then GM_Lag(y_tilde, [A_hat, WA_hat, X_tilde], W)\n",
        "def first_stage_A_hat(run_df, Z_cols, X_cols):\n",
        "    run = run_df.copy()\n",
        "    to_demean = [\"A\"] + Z_cols + [c for c in X_cols if c in run.columns]\n",
        "    run = demean_by(run, FE_KEY, to_demean)\n",
        "    # Only numeric columns for statsmodels (avoids object dtype)\n",
        "    exog = [c for c in (Z_cols + [c for c in X_cols if c in run.columns and run[c].notna().all()]) if pd.api.types.is_numeric_dtype(run[c])]\n",
        "    X = np.asarray(sm.add_constant(run[exog]), dtype=np.float64)\n",
        "    y_a = np.asarray(run[\"A\"], dtype=np.float64)\n",
        "    groups = run[FE_KEY].astype(str) if run[FE_KEY].dtype.name == \"category\" else run[FE_KEY]\n",
        "    mod = sm.OLS(y_a, X).fit(cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
        "    return mod.predict(X), mod\n",
        "\n",
        "def run_sdm_iv(run_df, W, Z_cols, X_cols):\n",
        "    run = run_df.copy()\n",
        "    A_hat, fs_mod = first_stage_A_hat(run, Z_cols, X_cols)\n",
        "    run[\"A_hat\"] = A_hat\n",
        "    run[\"WA_hat\"] = lag_spatial(W, A_hat)\n",
        "    to_demean = [\"y\", \"A_hat\", \"WA_hat\"] + [c for c in X_cols if c in run.columns]\n",
        "    run = demean_by(run, FE_KEY, to_demean)\n",
        "    exog_cols = [\"A_hat\", \"WA_hat\"] + [c for c in X_cols if c in run.columns and run[c].notna().all() and pd.api.types.is_numeric_dtype(run[c])]\n",
        "    X = np.asarray(run[exog_cols], dtype=np.float64)\n",
        "    y = np.asarray(run[\"y\"], dtype=np.float64)\n",
        "    # spreg.GM_Lag: y = rho*W*y + X*beta\n",
        "    try:\n",
        "        model = spreg.GM_Lag(y, X, w=W, name_y=\"y\", name_x=exog_cols)\n",
        "        rho = model.rho\n",
        "        # model.betas layout: [CONSTANT, exog_cols..., rho] — skip constant (idx 0)\n",
        "        betas = {\"rho\": float(np.asarray(rho).flat[0])}\n",
        "        for idx, name in enumerate(exog_cols):\n",
        "            betas[name] = float(np.asarray(model.betas[idx + 1]).flat[0])\n",
        "        return model, betas, run\n",
        "    except Exception as e:\n",
        "        return None, None, run\n",
        "\n",
        "# Impacts helper: direct/indirect/total (simplified decomposition)\n",
        "def compute_impacts(rho, W, beta_A, beta_WA):\n",
        "    rho = float(np.asarray(rho).flat[0])\n",
        "    beta_A = float(np.asarray(beta_A).flat[0])\n",
        "    beta_WA = float(np.asarray(beta_WA).flat[0])\n",
        "    # Simplified direct/indirect — avoids costly full matrix inverse\n",
        "    return {\"direct\": beta_A, \"indirect\": beta_WA, \"total\": beta_A + beta_WA}\n",
        "\n",
        "sdm_rows = []\n",
        "fs_rows = []\n",
        "impact_rows = []\n",
        "for sample in SAMPLES:\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            run, _ = build_run_df(sample, exposure, outcome)\n",
        "            if run is None or len(run) < 20:\n",
        "                continue\n",
        "            W = build_W_for_run(run)\n",
        "            if W is None:\n",
        "                continue\n",
        "            A_hat, fs_mod = first_stage_A_hat(run, INSTRUMENTS, X_COLS)\n",
        "            fs_rows.append({\n",
        "                \"sample\": sample, \"exposure\": exposure, \"outcome\": outcome,\n",
        "                \"N\": int(fs_mod.nobs), \"rsquared\": getattr(fs_mod, \"rsquared\", np.nan),\n",
        "            })\n",
        "            model, betas, _ = run_sdm_iv(run, W, INSTRUMENTS, X_COLS)\n",
        "            if model is not None and betas is not None:\n",
        "                for k, v in betas.items():\n",
        "                    sdm_rows.append({\"sample\": sample, \"exposure\": exposure, \"outcome\": outcome, \"term\": k, \"coef\": v})\n",
        "                if \"A_hat\" in betas and \"WA_hat\" in betas:\n",
        "                    imp = compute_impacts(model.rho, W, betas[\"A_hat\"], betas[\"WA_hat\"])\n",
        "                    for k, v in imp.items():\n",
        "                        impact_rows.append({\"sample\": sample, \"exposure\": exposure, \"outcome\": outcome, \"impact\": k, \"value\": v})\n",
        "\n",
        "pd.DataFrame(sdm_rows).to_csv(out_path(\"tables\", \"sdm_results_long.csv\"), index=False)\n",
        "pd.DataFrame(fs_rows).to_csv(out_path(\"tables\", \"first_stage_diagnostics.csv\"), index=False)\n",
        "pd.DataFrame(impact_rows).to_csv(out_path(\"tables\", \"impacts_sdm.csv\"), index=False)\n",
        "print(\"SDM done. Coefficients:\", len(sdm_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a55acfab",
      "metadata": {},
      "source": [
        "## I.1 Pemetaan Dampak Kesejahteraan\n",
        "\n",
        "Subsection:\n",
        "- **I.1.1** Jangkauan dan Kedekatan Dampak secara Geografis — peta eksposur/jarak dan outcome per desa.\n",
        "- **I.1.2** Identifikasi Pola Pengelompokan Kesejahteraan — peta LISA / pengelompokan spasial outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ecd873",
      "metadata": {},
      "source": [
        "## Impact from all SPBUN locations (lokasi_spbu-n.xlsx)\n",
        "\n",
        "Measure and plot impact using **all** coordinates in `Survey_Map/lokasi_spbu-n.xlsx`. Multiple maps for different angles: impact by exposure/outcome, SPBUN distribution, most-affected villages, and exposure intensity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e4872a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded SPBUN coordinates: 374\n",
            "Saved spbun_lokasi_distribution.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_A_v_log_lnpov_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_A_v_log_Wbasic_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker5_w1_lnpov_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker5_w1_Wbasic_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker10_w1_lnpov_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker10_w1_Wbasic_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_A_v_log_lnpov_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_A_v_log_Wbasic_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker5_w1_lnpov_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker5_w1_Wbasic_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker10_w1_lnpov_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_all_spbun_Ker10_w1_Wbasic_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_most_affected_lnpov_A_v_log_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_most_affected_lnpov_A_v_log_ALL.png\n",
            "Saved exposure_intensity_spbun_10km_COAST.png\n",
            "Saved exposure_intensity_spbun_10km_ALL.png\n",
            "Saved exposure_intensity_spbun_5km_COAST.png\n",
            "Saved exposure_intensity_spbun_5km_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_compare_lnpov_vs_Wbasic_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved impact_compare_lnpov_vs_Wbasic_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved lisa_impact_dy_lnpov_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved lisa_impact_dy_Wbasic_z_COAST.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved lisa_impact_dy_lnpov_z_ALL.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved lisa_impact_dy_Wbasic_z_ALL.png\n",
            "Saved lisa_intensity_5km_COAST.png\n",
            "Saved lisa_intensity_5km_ALL.png\n",
            "Saved lisa_intensity_10km_COAST.png\n",
            "Saved lisa_intensity_10km_ALL.png\n",
            "Saved lisa_intensity_5km_vs_10km_COAST.png\n",
            "Saved lisa_intensity_5km_vs_10km_ALL.png\n",
            "All SPBUN-coordinate maps done.\n"
          ]
        }
      ],
      "source": [
        "# Load all SPBUN coordinates from lokasi_spbu-n.xlsx (sheet Data, column Koordinat)\n",
        "PATH_SPBUN_XLSX = os.path.join(ROOT, \"lokasi_spbu-n.xlsx\")\n",
        "\n",
        "def haversine_km(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(np.minimum(a, 1)))\n",
        "    return R * c\n",
        "\n",
        "def load_spbun_coordinates(path):\n",
        "    df = pd.read_excel(path, sheet_name=\"Data\")\n",
        "    out = []\n",
        "    for v in df[\"Koordinat\"].dropna():\n",
        "        s = str(v).strip()\n",
        "        parts = s.replace(\",\", \" \").split()\n",
        "        if len(parts) >= 2:\n",
        "            try:\n",
        "                a, b = float(parts[0]), float(parts[1])\n",
        "                if -15 <= a <= 10 and 90 <= b <= 150:\n",
        "                    out.append((a, b))\n",
        "                elif -15 <= b <= 10 and 90 <= a <= 150:\n",
        "                    out.append((b, a))\n",
        "            except Exception:\n",
        "                pass\n",
        "    return out\n",
        "\n",
        "spbun_coords = load_spbun_coordinates(PATH_SPBUN_XLSX) if os.path.exists(PATH_SPBUN_XLSX) else []\n",
        "print(\"Loaded SPBUN coordinates:\", len(spbun_coords))\n",
        "\n",
        "def run_simulation_map_multi(sample, outcome, exposure, spbun_lat_lon_list):\n",
        "    \"\"\"Impact from all SPBUN locations (cumulative dA). Same controls (X_COLS), SDM multiplier.\"\"\"\n",
        "    if not spbun_lat_lon_list:\n",
        "        return None\n",
        "    run, _ = build_run_df(sample, exposure, outcome)\n",
        "    if run is None or len(run) < 20:\n",
        "        return None\n",
        "    W = build_W_for_run(run)\n",
        "    if W is None:\n",
        "        return None\n",
        "    lat = run[\"lat_v\"].values\n",
        "    lon = run[\"lon_v\"].values\n",
        "    n = len(run)\n",
        "    # Cumulative dA from all SPBUNs (linear approximation)\n",
        "    dA = np.zeros(n, dtype=np.float64)\n",
        "    for (slat, slon) in spbun_lat_lon_list:\n",
        "        D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(n)])\n",
        "        if exposure == \"A_v_log\":\n",
        "            dA += (-np.log1p(D))  # sum over sources\n",
        "        elif exposure == \"Ker5_w1\":\n",
        "            dA += (D <= 5).astype(np.float64)\n",
        "        elif exposure == \"Ker10_w1\":\n",
        "            dA += (D <= 10).astype(np.float64)\n",
        "    if exposure == \"A_v_log\":\n",
        "        dA = dA - run[\"A\"].values  # dA = A_new - A_current; A_new = sum we just computed\n",
        "    model, betas, _ = run_sdm_iv(run, W, INSTRUMENTS, X_COLS)\n",
        "    if model is None or betas is None:\n",
        "        return None\n",
        "    rho = float(np.asarray(betas.get(\"rho\", 0)).flat[0])\n",
        "    beta_A = float(np.asarray(betas.get(\"A_hat\", 0)).flat[0])\n",
        "    theta = float(np.asarray(betas.get(\"WA_hat\", 0)).flat[0])\n",
        "    WdA = lag_spatial(W, dA)\n",
        "    rhs = beta_A * dA + theta * WdA\n",
        "    # Solve (I - rho*W) @ dy = rhs directly (avoids kernel-crashing dense inverse)\n",
        "    A_mat = (sparse.eye(W.n) - rho * W.sparse).tocsc()\n",
        "    dy = sparse.linalg.spsolve(A_mat, rhs)\n",
        "    run = run.copy()\n",
        "    run[\"dy\"] = dy\n",
        "    run[\"dA\"] = dA\n",
        "    return run\n",
        "\n",
        "# ---- Map 1: SPBUN distribution only (all coordinates on basemap) ----\n",
        "if spbun_coords and BASEMAP is not None:\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "    slat = [c[0] for c in spbun_coords]\n",
        "    slon = [c[1] for c in spbun_coords]\n",
        "    ax.scatter(slon, slat, s=4, c=\"darkred\", alpha=0.6, label=f\"SPBUN (n={len(spbun_coords)})\")\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.set_title(\"Lokasi SPBUN (lokasi_spbu-n.xlsx) — distribusi geografis\")\n",
        "    ax.legend()\n",
        "    ax.set_aspect(\"equal\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path(\"maps\", \"spbun_lokasi_distribution.png\"), dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved spbun_lokasi_distribution.png\")\n",
        "\n",
        "# ---- Maps 2–4: Impact (Δy) from all file SPBUNs by exposure, with SPBUN overlay — Pesisir & full sample ----\n",
        "for sample in SAMPLES:\n",
        "    slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            sim = run_simulation_map_multi(sample, outcome, exposure, spbun_coords)\n",
        "            if sim is None:\n",
        "                print(f\"Skip multi {sample} {exposure} {outcome}\")\n",
        "                continue\n",
        "            fig, ax = plt.subplots(figsize=(20, 8))\n",
        "            if BASEMAP is not None:\n",
        "                BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "            sc = ax.scatter(sim[\"lon_v\"], sim[\"lat_v\"], c=sim[\"dy\"], s=2, cmap=\"RdBu\")\n",
        "            if spbun_coords:\n",
        "                ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=8, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "            plt.colorbar(sc, ax=ax, label=\"Δy (counterfactual)\")\n",
        "            ax.set_xlabel(\"Longitude\")\n",
        "            ax.set_ylabel(\"Latitude\")\n",
        "            ax.set_title(f\"Dampak dari semua lokasi SPBUN — {slab} — {exposure} — {outcome}\")\n",
        "            ax.legend(loc=\"upper right\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(out_path(\"maps\", f\"impact_all_spbun_{exposure}_{outcome}_{sample}.png\"), dpi=150)\n",
        "            plt.close()\n",
        "            print(\"Saved\", f\"impact_all_spbun_{exposure}_{outcome}_{sample}.png\")\n",
        "\n",
        "# # ---- Map 5: Villages most affected (top 10% |Δy|) — Pesisir & full sample, with SPBUN ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         sim = run_simulation_map_multi(sample, \"lnpov_z\", \"A_v_log\", spbun_coords)\n",
        "#         if sim is None:\n",
        "#             continue\n",
        "#         q90 = sim[\"dy\"].abs().quantile(0.9)\n",
        "#         top = sim[\"dy\"].abs() >= q90\n",
        "#         fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#         if BASEMAP is not None:\n",
        "#             BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#         ax.scatter(sim.loc[~top, \"lon_v\"], sim.loc[~top, \"lat_v\"], s=1, c=\"lightgray\", alpha=0.5)\n",
        "#         ax.scatter(sim.loc[top, \"lon_v\"], sim.loc[top, \"lat_v\"], c=sim.loc[top, \"dy\"], s=8, cmap=\"RdBu_r\")\n",
        "#         ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.6, label=\"SPBUN\")\n",
        "#         ax.set_xlabel(\"Longitude\")\n",
        "#         ax.set_ylabel(\"Latitude\")\n",
        "#         ax.set_title(f\"Desa paling terdampak (top 10% |Δy|) — {slab} — lnpov_z, A_v_log\")\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(out_path(\"maps\", f\"impact_most_affected_lnpov_A_v_log_{sample}.png\"), dpi=150)\n",
        "#         plt.close()\n",
        "#         print(\"Saved\", f\"impact_most_affected_lnpov_A_v_log_{sample}.png\")\n",
        "\n",
        "# # ---- Map 6: Exposure intensity 10 km — Pesisir & full sample ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         run, _ = build_run_df(sample, \"A_v_log\", \"lnpov_z\")\n",
        "#         if run is None or len(run) < 20:\n",
        "#             continue\n",
        "#         lat, lon = run[\"lat_v\"].values, run[\"lon_v\"].values\n",
        "#         count_10km = np.zeros(len(run))\n",
        "#         for (slat, slon) in spbun_coords:\n",
        "#             D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(len(run))])\n",
        "#             count_10km += (D <= 10).astype(np.float64)\n",
        "#         run = run.copy()\n",
        "#         run[\"n_spbun_10km\"] = count_10km\n",
        "#         fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#         if BASEMAP is not None:\n",
        "#             BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#         sc = ax.scatter(run[\"lon_v\"], run[\"lat_v\"], c=run[\"n_spbun_10km\"], s=2, cmap=\"YlOrRd\")\n",
        "#         ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "#         plt.colorbar(sc, ax=ax, label=\"Jumlah SPBUN dalam 10 km\")\n",
        "#         ax.set_xlabel(\"Longitude\")\n",
        "#         ax.set_ylabel(\"Latitude\")\n",
        "#         ax.set_title(f\"Intensitas kedekatan (10 km) — {slab}\")\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(out_path(\"maps\", f\"exposure_intensity_spbun_10km_{sample}.png\"), dpi=150)\n",
        "#         plt.close()\n",
        "#         print(\"Saved\", f\"exposure_intensity_spbun_10km_{sample}.png\")\n",
        "\n",
        "# # ---- Map 6b: Exposure intensity 5 km — Pesisir & full sample ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         run, _ = build_run_df(sample, \"A_v_log\", \"lnpov_z\")\n",
        "#         if run is None or len(run) < 20:\n",
        "#             continue\n",
        "#         lat, lon = run[\"lat_v\"].values, run[\"lon_v\"].values\n",
        "#         count_5km = np.zeros(len(run))\n",
        "#         for (slat, slon) in spbun_coords:\n",
        "#             D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(len(run))])\n",
        "#             count_5km += (D <= 5).astype(np.float64)\n",
        "#         run = run.copy()\n",
        "#         run[\"n_spbun_5km\"] = count_5km\n",
        "#         fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#         if BASEMAP is not None:\n",
        "#             BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#         sc = ax.scatter(run[\"lon_v\"], run[\"lat_v\"], c=run[\"n_spbun_5km\"], s=2, cmap=\"YlOrRd\")\n",
        "#         ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "#         plt.colorbar(sc, ax=ax, label=\"Jumlah SPBUN dalam 5 km\")\n",
        "#         ax.set_xlabel(\"Longitude\")\n",
        "#         ax.set_ylabel(\"Latitude\")\n",
        "#         ax.set_title(f\"Intensitas kedekatan (5 km) — {slab}\")\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(out_path(\"maps\", f\"exposure_intensity_spbun_5km_{sample}.png\"), dpi=150)\n",
        "#         plt.close()\n",
        "#         print(\"Saved\", f\"exposure_intensity_spbun_5km_{sample}.png\")\n",
        "\n",
        "# # ---- Map 7: Two-panel lnpov vs Wbasic impact — Pesisir & full sample, SPBUN overlay ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "#         for ax, outcome in [(ax1, \"lnpov_z\"), (ax2, \"Wbasic_z\")]:\n",
        "#             sim = run_simulation_map_multi(sample, outcome, \"A_v_log\", spbun_coords)\n",
        "#             if sim is None:\n",
        "#                 continue\n",
        "#             if BASEMAP is not None:\n",
        "#                 BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#             ax.scatter(sim[\"lon_v\"], sim[\"lat_v\"], c=sim[\"dy\"], s=2, cmap=\"RdBu_r\")\n",
        "#             ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5)\n",
        "#             ax.set_title(f\"Δy — {outcome} (A_v_log)\")\n",
        "#             ax.set_xlabel(\"Longitude\")\n",
        "#             ax.set_ylabel(\"Latitude\")\n",
        "#         plt.suptitle(f\"Perbandingan dampak — {slab}: lnpov_z vs Wbasic_z\")\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(out_path(\"maps\", f\"impact_compare_lnpov_vs_Wbasic_{sample}.png\"), dpi=150)\n",
        "#         plt.close()\n",
        "#         print(\"Saved\", f\"impact_compare_lnpov_vs_Wbasic_{sample}.png\")\n",
        "\n",
        "# # ---- Map 8: LISA of impact (Δy) — Pesisir & full sample, SPBUN overlay ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         for outcome in OUTCOMES:\n",
        "#             sim = run_simulation_map_multi(sample, outcome, \"A_v_log\", spbun_coords)\n",
        "#             if sim is None or len(sim) < 100:\n",
        "#                 continue\n",
        "#             W_sim = build_W_for_run(sim)\n",
        "#             if W_sim is None:\n",
        "#                 continue\n",
        "#             try:\n",
        "#                 lisa = Moran_Local(sim[\"dy\"].values.astype(np.float64), W_sim, permutations=199)\n",
        "#                 sig = lisa.p_sim < 0.05\n",
        "#                 q = np.full(len(sim), np.nan)\n",
        "#                 q[sig] = lisa.q[sig]\n",
        "#                 fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#                 if BASEMAP is not None:\n",
        "#                     BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#                 sc = ax.scatter(sim[\"lon_v\"], sim[\"lat_v\"], c=q, s=3, cmap=\"RdYlBu_r\", vmin=1, vmax=4)\n",
        "#                 ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "#                 cbar = plt.colorbar(sc, ax=ax)\n",
        "#                 cbar.set_ticks([1, 2, 3, 4])\n",
        "#                 cbar.set_ticklabels([\"HH\", \"LH\", \"LL\", \"HL\"])\n",
        "#                 cbar.set_label(\"LISA cluster (p<0.05)\")\n",
        "#                 ax.set_xlabel(\"Longitude\")\n",
        "#                 ax.set_ylabel(\"Latitude\")\n",
        "#                 ax.set_title(f\"LISA dampak (Δy) — {slab} — {outcome}\")\n",
        "#                 ax.legend(loc=\"upper right\")\n",
        "#                 plt.tight_layout()\n",
        "#                 plt.savefig(out_path(\"maps\", f\"lisa_impact_dy_{outcome}_{sample}.png\"), dpi=150)\n",
        "#                 plt.close()\n",
        "#                 print(\"Saved\", f\"lisa_impact_dy_{outcome}_{sample}.png\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"LISA impact skip {sample} {outcome}:\", e)\n",
        "\n",
        "# # ---- Map 9: LISA of exposure intensity (5 km) — Pesisir & full sample ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         run, _ = build_run_df(sample, \"A_v_log\", \"lnpov_z\")\n",
        "#         if run is None or len(run) < 100:\n",
        "#             continue\n",
        "#         lat, lon = run[\"lat_v\"].values, run[\"lon_v\"].values\n",
        "#         count_5km = np.zeros(len(run))\n",
        "#         for (slat, slon) in spbun_coords:\n",
        "#             D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(len(run))])\n",
        "#             count_5km += (D <= 5).astype(np.float64)\n",
        "#         run = run.copy()\n",
        "#         run[\"n_spbun_5km\"] = count_5km\n",
        "#         W_run = build_W_for_run(run)\n",
        "#         if W_run is not None:\n",
        "#             try:\n",
        "#                 lisa5 = Moran_Local(run[\"n_spbun_5km\"].values.astype(np.float64), W_run, permutations=199)\n",
        "#                 sig5 = lisa5.p_sim < 0.05\n",
        "#                 q5 = np.full(len(run), np.nan)\n",
        "#                 q5[sig5] = lisa5.q[sig5]\n",
        "#                 fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#                 if BASEMAP is not None:\n",
        "#                     BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#                 sc = ax.scatter(run[\"lon_v\"], run[\"lat_v\"], c=q5, s=3, cmap=\"RdYlBu_r\", vmin=1, vmax=4)\n",
        "#                 ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "#                 cbar = plt.colorbar(sc, ax=ax)\n",
        "#                 cbar.set_ticks([1, 2, 3, 4])\n",
        "#                 cbar.set_ticklabels([\"HH\", \"LH\", \"LL\", \"HL\"])\n",
        "#                 cbar.set_label(\"LISA cluster (p<0.05)\")\n",
        "#                 ax.set_xlabel(\"Longitude\")\n",
        "#                 ax.set_ylabel(\"Latitude\")\n",
        "#                 ax.set_title(f\"LISA intensitas 5 km — {slab}\")\n",
        "#                 ax.legend(loc=\"upper right\")\n",
        "#                 plt.tight_layout()\n",
        "#                 plt.savefig(out_path(\"maps\", f\"lisa_intensity_5km_{sample}.png\"), dpi=150)\n",
        "#                 plt.close()\n",
        "#                 print(\"Saved\", f\"lisa_intensity_5km_{sample}.png\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"LISA 5km skip\", sample, e)\n",
        "\n",
        "# # ---- Map 10: LISA of exposure intensity (10 km) — Pesisir & full sample ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         run, _ = build_run_df(sample, \"A_v_log\", \"lnpov_z\")\n",
        "#         if run is None or len(run) < 100:\n",
        "#             continue\n",
        "#         lat, lon = run[\"lat_v\"].values, run[\"lon_v\"].values\n",
        "#         count_10km = np.zeros(len(run))\n",
        "#         for (slat, slon) in spbun_coords:\n",
        "#             D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(len(run))])\n",
        "#             count_10km += (D <= 10).astype(np.float64)\n",
        "#         run = run.copy()\n",
        "#         run[\"n_spbun_10km\"] = count_10km\n",
        "#         W_run = build_W_for_run(run)\n",
        "#         if W_run is not None:\n",
        "#             try:\n",
        "#                 lisa10 = Moran_Local(run[\"n_spbun_10km\"].values.astype(np.float64), W_run, permutations=199)\n",
        "#                 sig10 = lisa10.p_sim < 0.05\n",
        "#                 q10 = np.full(len(run), np.nan)\n",
        "#                 q10[sig10] = lisa10.q[sig10]\n",
        "#                 fig, ax = plt.subplots(figsize=(14, 8))\n",
        "#                 if BASEMAP is not None:\n",
        "#                     BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#                 sc = ax.scatter(run[\"lon_v\"], run[\"lat_v\"], c=q10, s=3, cmap=\"RdYlBu_r\", vmin=1, vmax=4)\n",
        "#                 ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5, label=\"SPBUN\")\n",
        "#                 cbar = plt.colorbar(sc, ax=ax)\n",
        "#                 cbar.set_ticks([1, 2, 3, 4])\n",
        "#                 cbar.set_ticklabels([\"HH\", \"LH\", \"LL\", \"HL\"])\n",
        "#                 cbar.set_label(\"LISA cluster (p<0.05)\")\n",
        "#                 ax.set_xlabel(\"Longitude\")\n",
        "#                 ax.set_ylabel(\"Latitude\")\n",
        "#                 ax.set_title(f\"LISA intensitas 10 km — {slab}\")\n",
        "#                 ax.legend(loc=\"upper right\")\n",
        "#                 plt.tight_layout()\n",
        "#                 plt.savefig(out_path(\"maps\", f\"lisa_intensity_10km_{sample}.png\"), dpi=150)\n",
        "#                 plt.close()\n",
        "#                 print(\"Saved\", f\"lisa_intensity_10km_{sample}.png\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"LISA 10km skip\", sample, e)\n",
        "\n",
        "# # ---- Map 11: Two-panel LISA 5 km vs 10 km — Pesisir & full sample ----\n",
        "# if spbun_coords:\n",
        "#     for sample in SAMPLES:\n",
        "#         slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "#         run, _ = build_run_df(sample, \"A_v_log\", \"lnpov_z\")\n",
        "#         if run is None or len(run) < 100:\n",
        "#             continue\n",
        "#         lat, lon = run[\"lat_v\"].values, run[\"lon_v\"].values\n",
        "#         count_5km = np.zeros(len(run))\n",
        "#         count_10km = np.zeros(len(run))\n",
        "#         for (slat, slon) in spbun_coords:\n",
        "#             D = np.array([haversine_km(lat[i], lon[i], slat, slon) for i in range(len(run))])\n",
        "#             count_5km += (D <= 5).astype(np.float64)\n",
        "#             count_10km += (D <= 10).astype(np.float64)\n",
        "#         run = run.copy()\n",
        "#         run[\"n_spbun_5km\"], run[\"n_spbun_10km\"] = count_5km, count_10km\n",
        "#         W_run = build_W_for_run(run)\n",
        "#         if W_run is not None:\n",
        "#             try:\n",
        "#                 lisa5 = Moran_Local(run[\"n_spbun_5km\"].values.astype(np.float64), W_run, permutations=199)\n",
        "#                 lisa10 = Moran_Local(run[\"n_spbun_10km\"].values.astype(np.float64), W_run, permutations=199)\n",
        "#                 q5 = np.where(lisa5.p_sim < 0.05, lisa5.q, np.nan)\n",
        "#                 q10 = np.where(lisa10.p_sim < 0.05, lisa10.q, np.nan)\n",
        "#                 fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "#                 for ax, q, title in [(ax1, q5, \"5 km\"), (ax2, q10, \"10 km\")]:\n",
        "#                     if BASEMAP is not None:\n",
        "#                         BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "#                     sc = ax.scatter(run[\"lon_v\"], run[\"lat_v\"], c=q, s=3, cmap=\"RdYlBu_r\", vmin=1, vmax=4)\n",
        "#                     ax.scatter([c[1] for c in spbun_coords], [c[0] for c in spbun_coords], s=6, c=\"black\", marker=\".\", alpha=0.5)\n",
        "#                     ax.set_title(f\"LISA intensitas — {title}\")\n",
        "#                     ax.set_xlabel(\"Longitude\")\n",
        "#                     ax.set_ylabel(\"Latitude\")\n",
        "#                 plt.suptitle(f\"Perbandingan LISA intensitas — {slab}: 5 km vs 10 km\")\n",
        "#                 plt.tight_layout()\n",
        "#                 plt.savefig(out_path(\"maps\", f\"lisa_intensity_5km_vs_10km_{sample}.png\"), dpi=150)\n",
        "#                 plt.close()\n",
        "#                 print(\"Saved\", f\"lisa_intensity_5km_vs_10km_{sample}.png\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"LISA 5km vs 10km skip\", sample, e)\n",
        "\n",
        "# print(\"All SPBUN-coordinate maps done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "79715ba1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved welfare_COAST_lnpov_z.png\n",
            "Saved welfare_COAST_Wbasic_z.png\n",
            "Saved welfare_ALL_lnpov_z.png\n",
            "Saved welfare_ALL_Wbasic_z.png\n",
            "Saved proximity_COAST_A_v_log.png\n",
            "Saved proximity_COAST_Ker5_w1.png\n",
            "Saved proximity_COAST_Ker10_w1.png\n",
            "Saved proximity_ALL_A_v_log.png\n",
            "Saved proximity_ALL_Ker5_w1.png\n",
            "Saved proximity_ALL_Ker10_w1.png\n",
            "Saved lisa_COAST_lnpov_z.png\n",
            "Saved lisa_COAST_Wbasic_z.png\n",
            "Saved lisa_ALL_lnpov_z.png\n",
            "Saved lisa_ALL_Wbasic_z.png\n",
            "Saved compare_COAST_vs_ALL_lnpov_z.png\n",
            "Saved compare_COAST_vs_ALL_Wbasic_z.png\n",
            "I.1 / I.1.1 / I.1.2 maps done (Pesisir + full sample + comparison).\n"
          ]
        }
      ],
      "source": [
        "# --- I.1 & I.1.1 & I.1.2: Welfare maps, proximity/scope, clustering (basemap from Survey_Map) ---\n",
        "def plot_on_basemap(ax, lon, lat, c, title, cmap=\"viridis\", clabel=\"\", s=2):\n",
        "    if BASEMAP is not None:\n",
        "        BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "    sc = ax.scatter(lon, lat, c=c, s=s, cmap=cmap)\n",
        "    plt.colorbar(sc, ax=ax, label=clabel)\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "# I.1 — Pemetaan Dampak Kesejahteraan: outcome levels by village\n",
        "for sample in SAMPLES:\n",
        "    df = DATASETS[sample]\n",
        "    for outcome in OUTCOMES:\n",
        "        if outcome not in df.columns:\n",
        "            continue\n",
        "        r = df[[\"lat_v\", \"lon_v\", outcome]].dropna(how=\"any\")\n",
        "        if len(r) < 50:\n",
        "            continue\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "        slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "        plot_on_basemap(ax, r[\"lon_v\"], r[\"lat_v\"], r[outcome], f\"I.1 Kesejahteraan — {slab} — {outcome}\", clabel=outcome)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_path(\"maps\", f\"welfare_{sample}_{outcome}.png\"), dpi=150)\n",
        "        plt.close()\n",
        "        print(\"Saved\", f\"welfare_{sample}_{outcome}.png\")\n",
        "\n",
        "# I.1.1 — Jangkauan dan Kedekatan Dampak: exposure (proximity) by village\n",
        "for sample in SAMPLES:\n",
        "    df = DATASETS[sample]\n",
        "    for exp in [\"A_v_log\", \"Ker5_w1\", \"Ker10_w1\"]:\n",
        "        if exp not in df.columns:\n",
        "            continue\n",
        "        r = df[[\"lat_v\", \"lon_v\", exp]].dropna(how=\"any\")\n",
        "        if len(r) < 50:\n",
        "            continue\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "        slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "        plot_on_basemap(ax, r[\"lon_v\"], r[\"lat_v\"], r[exp], f\"I.1.1 Kedekatan — {slab} — {exp}\", clabel=exp)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_path(\"maps\", f\"proximity_{sample}_{exp}.png\"), dpi=150)\n",
        "        plt.close()\n",
        "        print(\"Saved\", f\"proximity_{sample}_{exp}.png\")\n",
        "\n",
        "# I.1.2 — Pola Pengelompokan Kesejahteraan: LISA (local Moran) clusters\n",
        "for sample in SAMPLES:\n",
        "    df = DATASETS[sample]\n",
        "    r = df[[\"lat_v\", \"lon_v\"] + [c for c in OUTCOMES if c in df.columns]].dropna(how=\"any\")\n",
        "    if len(r) < 100:\n",
        "        continue\n",
        "    W = build_W_for_run(r)\n",
        "    if W is None:\n",
        "        continue\n",
        "    for outcome in OUTCOMES:\n",
        "        if outcome not in r.columns:\n",
        "            continue\n",
        "        y = r[outcome].values.astype(np.float64)\n",
        "        try:\n",
        "            lisa = Moran_Local(y, W, permutations=199)\n",
        "            # 1=HH, 2=LH, 3=LL, 4=HL; use only significant (e.g. p<0.05)\n",
        "            sig = lisa.p_sim < 0.05\n",
        "            q = np.full(len(y), np.nan)\n",
        "            q[sig] = lisa.q[sig]\n",
        "            fig, ax = plt.subplots(figsize=(14, 8))\n",
        "            if BASEMAP is not None:\n",
        "                BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "            sc = ax.scatter(r[\"lon_v\"], r[\"lat_v\"], c=q, s=3, cmap=\"RdYlBu_r\", vmin=1, vmax=4)\n",
        "            cbar = plt.colorbar(sc, ax=ax, label=\"LISA cluster (1=HH,2=LH,3=LL,4=HL)\")\n",
        "            cbar.set_ticks([1, 2, 3, 4])\n",
        "            cbar.set_ticklabels([\"HH\", \"LH\", \"LL\", \"HL\"])\n",
        "            ax.set_xlabel(\"Longitude\")\n",
        "            ax.set_ylabel(\"Latitude\")\n",
        "            slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "            ax.set_title(f\"I.1.2 Pengelompokan Kesejahteraan — {slab} — {outcome} (LISA, p<0.05)\")\n",
        "            ax.set_aspect(\"equal\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(out_path(\"maps\", f\"lisa_{sample}_{outcome}.png\"), dpi=150)\n",
        "            plt.close()\n",
        "            print(\"Saved\", f\"lisa_{sample}_{outcome}.png\")\n",
        "        except Exception as e:\n",
        "            print(f\"LISA skip {sample} {outcome}:\", e)\n",
        "\n",
        "# --- Comparison: Pesisir vs Seluruh desa (side-by-side) to see impact on neighbouring non-coastal villages ---\n",
        "for outcome in OUTCOMES:\n",
        "    data = {}\n",
        "    for sample in SAMPLES:\n",
        "        df = DATASETS[sample]\n",
        "        if outcome not in df.columns:\n",
        "            continue\n",
        "        r = df[[\"lat_v\", \"lon_v\", outcome]].dropna(how=\"any\")\n",
        "        if len(r) < 50:\n",
        "            continue\n",
        "        data[sample] = r\n",
        "    if \"COAST\" not in data or \"ALL\" not in data:\n",
        "        continue\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    plot_on_basemap(ax1, data[\"COAST\"][\"lon_v\"], data[\"COAST\"][\"lat_v\"], data[\"COAST\"][outcome], f\"Pesisir — {outcome}\", clabel=outcome, s=3)\n",
        "    plot_on_basemap(ax2, data[\"ALL\"][\"lon_v\"], data[\"ALL\"][\"lat_v\"], data[\"ALL\"][outcome], f\"Seluruh desa (incl. non-pesisir) — {outcome}\", clabel=outcome, s=1)\n",
        "    plt.suptitle(f\"I.1 Perbandingan: Pesisir vs Seluruh desa — {outcome}\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path(\"maps\", f\"compare_COAST_vs_ALL_{outcome}.png\"), dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", f\"compare_COAST_vs_ALL_{outcome}.png\")\n",
        "\n",
        "print(\"I.1 / I.1.1 / I.1.2 maps done (Pesisir + full sample + comparison).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb3d178",
      "metadata": {},
      "source": [
        "## M7 — SEM with ring-threshold terms (A0_5, A5_10, A10_15); spatial error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5f212f2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEM ring done. Rows: 52\n"
          ]
        }
      ],
      "source": [
        "# M7: Ring exposures from C5/C10/C15 or Ker5/Ker10/Ker15; then GM_Error\n",
        "def add_ring_exposure(df):\n",
        "    d = df.copy()\n",
        "    if \"C5_w1\" in d.columns and \"C10_w1\" in d.columns and \"C15_w1\" in d.columns:\n",
        "        d[\"A0_5\"] = d[\"C5_w1\"]\n",
        "        d[\"A5_10\"] = (d[\"C10_w1\"] - d[\"C5_w1\"]).clip(lower=0)\n",
        "        d[\"A10_15\"] = (d[\"C15_w1\"] - d[\"C10_w1\"]).clip(lower=0)\n",
        "    elif \"Ker5_w1\" in d.columns and \"Ker10_w1\" in d.columns:\n",
        "        d[\"A0_5\"] = d[\"Ker5_w1\"]\n",
        "        d[\"A5_10\"] = (d[\"Ker10_w1\"] - d[\"Ker5_w1\"]).clip(lower=0)\n",
        "        d[\"A10_15\"] = (d[\"Ker15_w1\"] - d[\"Ker10_w1\"]).clip(lower=0) if \"Ker15_w1\" in d.columns else 0.0\n",
        "    else:\n",
        "        d[\"A0_5\"] = np.nan\n",
        "        d[\"A5_10\"] = np.nan\n",
        "        d[\"A10_15\"] = np.nan\n",
        "    return d\n",
        "\n",
        "RING_COLS = [\"A0_5\", \"A5_10\", \"A10_15\"]\n",
        "\n",
        "sem_rows = []\n",
        "sem_lambda_rows = []\n",
        "for sample in SAMPLES:\n",
        "    run = DATASETS[sample].copy()\n",
        "    run = add_ring_exposure(run)\n",
        "    for outcome in OUTCOMES:\n",
        "        if outcome not in run.columns:\n",
        "            continue\n",
        "        run[\"y\"] = run[outcome]\n",
        "        req = [\"iddesa\", FE_KEY, \"lat_v\", \"lon_v\", \"y\"] + RING_COLS + X_COLS\n",
        "        req = [c for c in req if c in run.columns]\n",
        "        r = run[req].dropna(how=\"any\")\n",
        "        if len(r) < 20:\n",
        "            continue\n",
        "        W = build_W_for_run(r)\n",
        "        if W is None:\n",
        "            continue\n",
        "        r = demean_by(r, FE_KEY, [\"y\"] + RING_COLS + [c for c in X_COLS if c in r.columns])\n",
        "        exog = [c for c in RING_COLS + X_COLS if c in r.columns and r[c].notna().all() and pd.api.types.is_numeric_dtype(r[c])]\n",
        "        if len(exog) < 2:\n",
        "            continue\n",
        "        X = np.asarray(r[exog], dtype=np.float64)\n",
        "        y = np.asarray(r[\"y\"], dtype=np.float64)\n",
        "        try:\n",
        "            model = spreg.GM_Error(y, X, w=W, name_x=exog)\n",
        "            # GM_Error has no .lam; spatial coefficient lambda is last in model.betas\n",
        "            lam = float(np.asarray(model.betas).flat[-1])\n",
        "            nk = len(model.betas.flat)\n",
        "            lambda_se = float(model.std_err.flat[-1]) if len(model.std_err.flat) >= nk else np.nan\n",
        "            sem_lambda_rows.append({\"sample\": sample, \"outcome\": outcome, \"lambda\": lam, \"lambda_se\": lambda_se})\n",
        "            for i, name in enumerate(exog):\n",
        "                sem_rows.append({\"sample\": sample, \"outcome\": outcome, \"term\": name, \"coef\": model.betas[i], \"se\": np.sqrt(model.vm[i, i])})\n",
        "        except Exception as e:\n",
        "            print(\"SEM skip\", sample, outcome, e)\n",
        "\n",
        "pd.DataFrame(sem_rows).to_csv(out_path(\"tables\", \"sem_ring_results_long.csv\"), index=False)\n",
        "pd.DataFrame(sem_lambda_rows).to_csv(out_path(\"tables\", \"sem_lambda_table.csv\"), index=False)\n",
        "print(\"SEM ring done. Rows:\", len(sem_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32d93606",
      "metadata": {},
      "source": [
        "## Simulation map: new SPBUN → Δy (A_v_log, Ker5_w1, Ker10_w1) — full sample (ALL) with controls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27398354",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_A_v_log_COAST_lnpov_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_A_v_log_COAST_Wbasic_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_Ker5_w1_COAST_lnpov_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_Ker5_w1_COAST_Wbasic_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_Ker10_w1_COAST_lnpov_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sim_dy_Ker10_w1_COAST_Wbasic_z.png\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:606: SparseEfficiencyWarning: splu converted its input to CSC format\n",
            "  return splu(A).solve\n",
            "/Users/athamawardi/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/scipy/sparse/linalg/_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  Ainv = spsolve(A, I)\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Counterfactual: one hypothetical SPBUN location; compute ΔA = A_new - A_current; Δy from SDM multiplier\n",
        "# Supports A_v_log, Ker5_w1, Ker10_w1. Uses full sample (ALL) with controls (X_COLS).\n",
        "# Note: haversine_km is already defined above (SPBUN multi-map cell)\n",
        "\n",
        "def run_simulation_map(sample, outcome, exposure, new_spbun_lat, new_spbun_lon):\n",
        "    run, _ = build_run_df(sample, exposure, outcome)\n",
        "    if run is None or len(run) < 20:\n",
        "        return None\n",
        "    W = build_W_for_run(run)\n",
        "    if W is None:\n",
        "        return None\n",
        "    lat = run[\"lat_v\"].values\n",
        "    lon = run[\"lon_v\"].values\n",
        "    D_new = np.array([haversine_km(lat[i], lon[i], new_spbun_lat, new_spbun_lon) for i in range(len(run))])\n",
        "    A_cur = run[\"A\"].values\n",
        "    if exposure == \"A_v_log\":\n",
        "        A_new = -np.log1p(D_new)\n",
        "        dA = A_new - A_cur\n",
        "    elif exposure == \"Ker5_w1\":\n",
        "        dA = (D_new <= 5).astype(np.float64)  # +1 SPBUN within 5 km\n",
        "    elif exposure == \"Ker10_w1\":\n",
        "        dA = (D_new <= 10).astype(np.float64)  # +1 SPBUN within 10 km\n",
        "    else:\n",
        "        return None\n",
        "    # SDM: Δy = (I - ρW)^{-1} (β*dA + θ*W*dA). Same controls (X_COLS) as main SDM.\n",
        "    model, betas, _ = run_sdm_iv(run, W, INSTRUMENTS, X_COLS)\n",
        "    if model is None or betas is None:\n",
        "        return None\n",
        "    rho = float(np.asarray(betas.get(\"rho\", 0)).flat[0])\n",
        "    beta_A = float(np.asarray(betas.get(\"A_hat\", 0)).flat[0])\n",
        "    theta = float(np.asarray(betas.get(\"WA_hat\", 0)).flat[0])\n",
        "    WdA = lag_spatial(W, dA)\n",
        "    rhs = beta_A * dA + theta * WdA\n",
        "    # Solve (I - rho*W) @ dy = rhs directly (avoids kernel-crashing dense inverse)\n",
        "    A_mat = (sparse.eye(W.n) - rho * W.sparse).tocsc()\n",
        "    dy = sparse.linalg.spsolve(A_mat, rhs)\n",
        "    run = run.copy()\n",
        "    run[\"dy\"] = dy\n",
        "    return run\n",
        "\n",
        "# Hypothetical SPBUN at -6.2, 106.8 (Java). Plot for Pesisir (COAST) and full sample (ALL) with controls; all three exposures.\n",
        "NEW_SPBUN_LAT, NEW_SPBUN_LON = -6.2, 106.8\n",
        "for sample in SAMPLES:\n",
        "    slab = \"Pesisir\" if sample == \"COAST\" else \"Seluruh desa (incl. non-pesisir)\"\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            sim = run_simulation_map(sample, outcome, exposure, NEW_SPBUN_LAT, NEW_SPBUN_LON)\n",
        "            if sim is None:\n",
        "                print(f\"Skip sim {sample} {exposure} {outcome}\")\n",
        "                continue\n",
        "            fig, ax = plt.subplots(figsize=(20, 8))\n",
        "            if BASEMAP is not None:\n",
        "                BASEMAP.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"darkgrey\", linewidth=0.5, zorder=0)\n",
        "            sc = ax.scatter(sim[\"lon_v\"], sim[\"lat_v\"], c=sim[\"dy\"], s=1, cmap=\"RdBu_r\")\n",
        "            plt.colorbar(sc, ax=ax, label=\"Δy (counterfactual)\")\n",
        "            ax.set_xlabel(\"Longitude\")\n",
        "            ax.set_ylabel(\"Latitude\")\n",
        "            ax.set_title(f\"Δy — {slab} — {exposure} — {outcome} (controls: X_COLS)\")\n",
        "            plt.tight_layout()\n",
        "            fname = f\"sim_dy_{exposure}_{sample}_{outcome}.png\"\n",
        "            plt.savefig(out_path(\"maps\", fname), dpi=150)\n",
        "            plt.close()\n",
        "            print(\"Saved\", fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61ea319",
      "metadata": {},
      "source": [
        "## Model comparison (residual Moran, key coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e011ac",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/athamawardi/Desktop/Research-Projects/PSE_Pertamina/outputs/tables/slx_post_moran.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     23\u001b[39m         comparison.append({\n\u001b[32m     24\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     25\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbaseline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmoran_p\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mp_value\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     26\u001b[39m         })\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# From M5\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtables\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mslx_post_moran.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.iterrows():\n\u001b[32m     29\u001b[39m     comparison.append({\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSLX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmoran_i\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mmoran_i\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     32\u001b[39m     })\n\u001b[32m     33\u001b[39m     comparison.append({\n\u001b[32m     34\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSLX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmoran_p\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mp_value\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     36\u001b[39m     })\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/athamawardi/Desktop/Research-Projects/PSE_Pertamina/outputs/tables/slx_post_moran.csv'"
          ]
        }
      ],
      "source": [
        "# Assemble comparison: baseline residual Moran (M4), SLX post Moran, SDM post Moran (optional), SEM lambda\n",
        "\n",
        "# Ensure moran_df is available (load from CSV if not in memory after kernel restart)\n",
        "try:\n",
        "    moran_df\n",
        "except NameError:\n",
        "    _moran_csv = out_path(\"tables\", \"moran_results.csv\")\n",
        "    if os.path.exists(_moran_csv):\n",
        "        moran_df = pd.read_csv(_moran_csv)\n",
        "        print(\"(Loaded moran_df from CSV)\")\n",
        "    else:\n",
        "        moran_df = pd.DataFrame(columns=[\"sample\", \"outcome\", \"exposure\", \"target\", \"moran_i\", \"p_value\"])\n",
        "        print(\"WARNING: moran_df not available — run M4 cell first\")\n",
        "\n",
        "comparison = []\n",
        "# From M4\n",
        "for _, row in moran_df.iterrows():\n",
        "    if row[\"target\"] == \"uhat_baseline\":\n",
        "        comparison.append({\n",
        "            \"sample\": row[\"sample\"], \"outcome\": row[\"outcome\"], \"exposure\": row[\"exposure\"],\n",
        "            \"model\": \"baseline\", \"metric\": \"moran_i\", \"value\": row[\"moran_i\"],\n",
        "        })\n",
        "        comparison.append({\n",
        "            \"sample\": row[\"sample\"], \"outcome\": row[\"outcome\"], \"exposure\": row[\"exposure\"],\n",
        "            \"model\": \"baseline\", \"metric\": \"moran_p\", \"value\": row[\"p_value\"],\n",
        "        })\n",
        "# From M5\n",
        "for _, row in pd.read_csv(out_path(\"tables\", \"slx_post_moran.csv\")).iterrows():\n",
        "    comparison.append({\n",
        "        \"sample\": row[\"sample\"], \"outcome\": row[\"outcome\"], \"exposure\": row[\"exposure\"],\n",
        "        \"model\": \"SLX\", \"metric\": \"moran_i\", \"value\": row[\"moran_i\"],\n",
        "    })\n",
        "    comparison.append({\n",
        "        \"sample\": row[\"sample\"], \"outcome\": row[\"outcome\"], \"exposure\": row[\"exposure\"],\n",
        "        \"model\": \"SLX\", \"metric\": \"moran_p\", \"value\": row[\"p_value\"],\n",
        "    })\n",
        "comp_df = pd.DataFrame(comparison)\n",
        "comp_df.to_csv(out_path(\"tables\", \"model_comparison_moran.csv\"), index=False)\n",
        "print(comp_df.head(20).to_string())\n",
        "print(\"\\nFull comparison saved to Output/tsls/tables/model_comparison_moran.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4ae069",
      "metadata": {},
      "source": [
        "## Goodness of Fit — RMSE, R², MAE, AIC, BIC across all models\n",
        "\n",
        "Compare **Baseline IV2SLS** (from Stata village-values), **M5 SLX**, **M6 SDM (GM_Lag)**, and **M7 SEM (GM_Error)** using standard GOF metrics:\n",
        "\n",
        "- **RMSE** — Root Mean Square Error (lower = better)\n",
        "- **MAE** — Mean Absolute Error (lower = better)\n",
        "- **R² / pseudo-R²** — Variance explained (higher = better)\n",
        "- **Adj. R²** — Adjusted R² (OLS-based models only)\n",
        "- **AIC / BIC** — Information Criteria (lower = better, OLS only)\n",
        "- **Log-Lik** — Log-Likelihood (OLS only)\n",
        "- **σ²** — Error variance estimate\n",
        "- **Moran I (resid)** — Residual spatial autocorrelation (closer to 0 = better)\n",
        "- **N** — Sample size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf0f209",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "1. Baseline IV2SLS GOF (from Stata village-values)\n",
            "======================================================================\n",
            "sample exposure  outcome     N     RMSE      MAE       R2\n",
            " COAST  A_v_log  lnpov_z 12966 0.694043 0.529705 0.188506\n",
            " COAST  A_v_log Wbasic_z 12966 0.438396 0.342761 0.191638\n",
            "   ALL  A_v_log  lnpov_z 84276 0.651414 0.483291 0.110459\n",
            "   ALL  A_v_log Wbasic_z 84276 0.424332 0.326337 0.090292\n",
            " COAST  Ker5_w1  lnpov_z 12966 0.720343 0.550410 0.084113\n",
            " COAST  Ker5_w1 Wbasic_z 12966 0.453430 0.352476 0.091058\n",
            "   ALL  Ker5_w1  lnpov_z 84276 0.659338 0.488932 0.020050\n",
            "   ALL  Ker5_w1 Wbasic_z 84276 0.429031 0.329834 0.013154\n",
            " COAST Ker10_w1  lnpov_z 12966 0.714318 0.546152 0.160156\n",
            " COAST Ker10_w1 Wbasic_z 12966 0.450209 0.351355 0.166300\n",
            "   ALL Ker10_w1  lnpov_z 84276 0.658657 0.489105 0.039231\n",
            "   ALL Ker10_w1 Wbasic_z 84276 0.428916 0.330240 0.027777\n",
            "\n",
            "======================================================================\n",
            "2. M5 SLX GOF\n",
            "======================================================================\n",
            "  SLX skip: COAST/A_v_log/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: COAST/A_v_log/Wbasic_z — name 'run_slx' is not defined\n",
            "  SLX skip: COAST/Ker5_w1/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: COAST/Ker5_w1/Wbasic_z — name 'run_slx' is not defined\n",
            "  SLX skip: COAST/Ker10_w1/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: COAST/Ker10_w1/Wbasic_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/A_v_log/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/A_v_log/Wbasic_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/Ker5_w1/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/Ker5_w1/Wbasic_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/Ker10_w1/lnpov_z — name 'run_slx' is not defined\n",
            "  SLX skip: ALL/Ker10_w1/Wbasic_z — name 'run_slx' is not defined\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"None of [Index(['sample', 'exposure', 'outcome', 'N', 'RMSE', 'MAE', 'R2', 'sm_AIC',\\n       'sm_BIC', 'Moran_I_resid'],\\n      dtype='object')] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    152\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  SLX skip: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexposure\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m — \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m slx_gof = pd.DataFrame([r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m gof_rows \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mM5_SLX\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mslx_gof\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msample\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexposure\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutcome\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRMSE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mR2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msm_AIC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msm_BIC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMoran_I_resid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# ==================================================================\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# 3. M6 — SDM / GM_Lag (re-run to capture GOF from spreg object)\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# ==================================================================\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/playgroundenv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyError\u001b[39m: \"None of [Index(['sample', 'exposure', 'outcome', 'N', 'RMSE', 'MAE', 'R2', 'sm_AIC',\\n       'sm_BIC', 'Moran_I_resid'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Goodness-of-Fit computation across all models\n",
        "# Baseline IV2SLS (Stata), M5 SLX, M6 SDM (GM_Lag), M7 SEM (GM_Error)\n",
        "# ============================================================\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Ensure moran_df is available (load from CSV if not in memory after kernel restart)\n",
        "try:\n",
        "    moran_df\n",
        "except NameError:\n",
        "    _moran_csv = out_path(\"tables\", \"moran_results.csv\")\n",
        "    if os.path.exists(_moran_csv):\n",
        "        moran_df = pd.read_csv(_moran_csv)\n",
        "        print(\"(Loaded moran_df from CSV)\")\n",
        "    else:\n",
        "        moran_df = pd.DataFrame(columns=[\"sample\", \"outcome\", \"exposure\", \"target\", \"moran_i\", \"p_value\"])\n",
        "        print(\"WARNING: moran_df not available — run M4 cell first for Moran I values\")\n",
        "\n",
        "gof_rows = []\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Helper: compute standard GOF metrics from y and residuals/predicted\n",
        "# ------------------------------------------------------------------\n",
        "def compute_gof(y_true, y_pred, model_name, sample, exposure, outcome, n_params=None, extra=None):\n",
        "    \"\"\"Compute RMSE, MAE, R², and optionally AIC/BIC from arrays.\"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float).ravel()\n",
        "    y_pred = np.asarray(y_pred, dtype=float).ravel()\n",
        "    resid = y_true - y_pred\n",
        "    n = len(y_true)\n",
        "\n",
        "    rmse = np.sqrt(np.mean(resid ** 2))\n",
        "    mae = np.mean(np.abs(resid))\n",
        "    ss_res = np.sum(resid ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
        "    sigma2 = ss_res / n\n",
        "\n",
        "    row = {\n",
        "        \"sample\": sample, \"exposure\": exposure, \"outcome\": outcome,\n",
        "        \"model\": model_name, \"N\": n,\n",
        "        \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"sigma2\": sigma2,\n",
        "    }\n",
        "\n",
        "    # Adjusted R², AIC, BIC, Log-Lik (meaningful for OLS-based)\n",
        "    if n_params is not None and n_params > 0:\n",
        "        k = n_params\n",
        "        adj_r2 = 1.0 - (1.0 - r2) * (n - 1) / (n - k - 1) if n > k + 1 else np.nan\n",
        "        # Log-likelihood under normality: -n/2 * ln(2*pi*sigma2) - n/2\n",
        "        ll = -n / 2.0 * (np.log(2 * np.pi * sigma2) + 1) if sigma2 > 0 else np.nan\n",
        "        aic = 2 * k - 2 * ll if not np.isnan(ll) else np.nan\n",
        "        bic = k * np.log(n) - 2 * ll if not np.isnan(ll) else np.nan\n",
        "        row.update({\"adj_R2\": adj_r2, \"AIC\": aic, \"BIC\": bic, \"LogLik\": ll})\n",
        "    else:\n",
        "        row.update({\"adj_R2\": np.nan, \"AIC\": np.nan, \"BIC\": np.nan, \"LogLik\": np.nan})\n",
        "\n",
        "    # Merge any extra fields (e.g. Moran I)\n",
        "    if extra:\n",
        "        row.update(extra)\n",
        "    return row\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 1. BASELINE IV2SLS (from Stata village_values)\n",
        "#    y_actual = W_hat + uhat  →  y_pred = W_hat  →  residual = uhat\n",
        "# ==================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"1. Baseline IV2SLS GOF (from Stata village-values)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for exposure in EXPOSURES:\n",
        "    for v_suffix in [\"v1\"]:\n",
        "        key = (exposure, v_suffix)\n",
        "        if key not in BASELINE_VALUES:\n",
        "            continue\n",
        "        vv = BASELINE_VALUES[key].copy()\n",
        "        for sample in SAMPLES:\n",
        "            for outcome in OUTCOMES:\n",
        "                sub = vv[(vv[\"sample\"] == sample) & (vv[\"outcome\"] == outcome) &\n",
        "                         (vv[\"spec\"] == BASELINE_SPEC)].copy()\n",
        "                if len(sub) < 10:\n",
        "                    continue\n",
        "                sub[\"uhat\"] = pd.to_numeric(sub[\"uhat\"], errors=\"coerce\")\n",
        "                sub[\"W_hat\"] = pd.to_numeric(sub[\"W_hat\"], errors=\"coerce\")\n",
        "                sub = sub.dropna(subset=[\"uhat\", \"W_hat\"])\n",
        "                if len(sub) < 10:\n",
        "                    continue\n",
        "                y_actual = sub[\"W_hat\"].values + sub[\"uhat\"].values\n",
        "                y_pred = sub[\"W_hat\"].values\n",
        "\n",
        "                # Moran I on baseline residuals (reuse from M4 if available)\n",
        "                moran_val = np.nan\n",
        "                m4_match = moran_df[(moran_df[\"sample\"] == sample) &\n",
        "                                    (moran_df[\"outcome\"] == outcome) &\n",
        "                                    (moran_df[\"exposure\"] == exposure) &\n",
        "                                    (moran_df[\"target\"] == \"uhat_baseline\")]\n",
        "                if len(m4_match) > 0:\n",
        "                    moran_val = m4_match.iloc[0][\"moran_i\"]\n",
        "\n",
        "                row = compute_gof(y_actual, y_pred, \"Baseline_IV2SLS\", sample, exposure, outcome,\n",
        "                                  extra={\"Moran_I_resid\": moran_val})\n",
        "                gof_rows.append(row)\n",
        "\n",
        "baseline_gof = pd.DataFrame([r for r in gof_rows if r[\"model\"] == \"Baseline_IV2SLS\"])\n",
        "print(baseline_gof[[\"sample\", \"exposure\", \"outcome\", \"N\", \"RMSE\", \"MAE\", \"R2\"]].to_string(index=False))\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 2. M5 — SLX (re-run to capture full GOF)\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"2. M5 SLX GOF\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for sample in SAMPLES:\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            run, _ = build_run_df(sample, exposure, outcome)\n",
        "            if run is None or len(run) < 20:\n",
        "                continue\n",
        "            W = build_W_for_run(run)\n",
        "            if W is None:\n",
        "                continue\n",
        "            try:\n",
        "                mod, resid, exog = run_slx(run, W, X_COLS)\n",
        "                y_true = run[\"y\"].values\n",
        "                y_pred = y_true - resid  # fitted = y - residual\n",
        "\n",
        "                # Moran I on SLX residuals\n",
        "                mi = Moran(resid, W, permutations=999)\n",
        "\n",
        "                # n_params: const + exog\n",
        "                k = len(exog) + 1  # +1 for constant\n",
        "\n",
        "                row = compute_gof(y_true, y_pred, \"M5_SLX\", sample, exposure, outcome,\n",
        "                                  n_params=k,\n",
        "                                  extra={\n",
        "                                      \"Moran_I_resid\": mi.I,\n",
        "                                      \"Moran_p_resid\": mi.p_sim,\n",
        "                                      # Also pull from statsmodels directly\n",
        "                                      \"sm_R2\": mod.rsquared,\n",
        "                                      \"sm_adj_R2\": mod.rsquared_adj,\n",
        "                                      \"sm_AIC\": mod.aic,\n",
        "                                      \"sm_BIC\": mod.bic,\n",
        "                                      \"sm_LogLik\": mod.llf,\n",
        "                                      \"F_stat\": mod.fvalue,\n",
        "                                      \"F_pvalue\": mod.f_pvalue,\n",
        "                                  })\n",
        "                gof_rows.append(row)\n",
        "            except Exception as e:\n",
        "                print(f\"  SLX skip: {sample}/{exposure}/{outcome} — {e}\")\n",
        "\n",
        "slx_gof = pd.DataFrame([r for r in gof_rows if r[\"model\"] == \"M5_SLX\"])\n",
        "print(slx_gof[[\"sample\", \"exposure\", \"outcome\", \"N\", \"RMSE\", \"MAE\", \"R2\", \"sm_AIC\", \"sm_BIC\", \"Moran_I_resid\"]].to_string(index=False))\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 3. M6 — SDM / GM_Lag (re-run to capture GOF from spreg object)\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"3. M6 SDM (GM_Lag) GOF\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for sample in SAMPLES:\n",
        "    for exposure in EXPOSURES:\n",
        "        for outcome in OUTCOMES:\n",
        "            run, _ = build_run_df(sample, exposure, outcome)\n",
        "            if run is None or len(run) < 20:\n",
        "                continue\n",
        "            W = build_W_for_run(run)\n",
        "            if W is None:\n",
        "                continue\n",
        "            try:\n",
        "                model, betas, run_dm = run_sdm_iv(run, W, INSTRUMENTS, X_COLS)\n",
        "                if model is None:\n",
        "                    continue\n",
        "\n",
        "                y_true = np.asarray(run_dm[\"y\"], dtype=np.float64).ravel()\n",
        "                resid = np.asarray(model.u).ravel()\n",
        "                y_pred = np.asarray(model.predy).ravel()\n",
        "\n",
        "                # Moran I on SDM residuals\n",
        "                mi = Moran(resid, W, permutations=999)\n",
        "\n",
        "                # spreg pseudo-R²\n",
        "                pr2 = getattr(model, \"pr2\", np.nan)\n",
        "                pr2_e = getattr(model, \"pr2_e\", np.nan)\n",
        "                sig2 = getattr(model, \"sig2\", np.nan)\n",
        "                rho = getattr(model, \"rho\", np.nan)\n",
        "\n",
        "                k = model.k if hasattr(model, \"k\") else np.nan\n",
        "                n = model.n if hasattr(model, \"n\") else len(y_true)\n",
        "\n",
        "                row = compute_gof(y_true, y_pred, \"M6_SDM\", sample, exposure, outcome,\n",
        "                                  n_params=int(k) if not np.isnan(k) else None,\n",
        "                                  extra={\n",
        "                                      \"Moran_I_resid\": mi.I,\n",
        "                                      \"Moran_p_resid\": mi.p_sim,\n",
        "                                      \"pseudo_R2\": pr2,\n",
        "                                      \"pseudo_R2_e\": pr2_e,\n",
        "                                      \"rho\": rho,\n",
        "                                      \"spreg_sig2\": sig2,\n",
        "                                  })\n",
        "                gof_rows.append(row)\n",
        "            except Exception as e:\n",
        "                print(f\"  SDM skip: {sample}/{exposure}/{outcome} — {e}\")\n",
        "\n",
        "sdm_gof = pd.DataFrame([r for r in gof_rows if r[\"model\"] == \"M6_SDM\"])\n",
        "if len(sdm_gof) > 0:\n",
        "    print(sdm_gof[[\"sample\", \"exposure\", \"outcome\", \"N\", \"RMSE\", \"MAE\", \"R2\", \"pseudo_R2\", \"rho\", \"Moran_I_resid\"]].to_string(index=False))\n",
        "else:\n",
        "    print(\"  (no SDM results)\")\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 4. M7 — SEM / GM_Error (re-run to capture GOF)\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"4. M7 SEM (GM_Error) GOF\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for sample in SAMPLES:\n",
        "    run_full = DATASETS[sample].copy()\n",
        "    run_full = add_ring_exposure(run_full)\n",
        "    for outcome in OUTCOMES:\n",
        "        if outcome not in run_full.columns:\n",
        "            continue\n",
        "        run_full[\"y\"] = run_full[outcome]\n",
        "        req = [\"iddesa\", FE_KEY, \"lat_v\", \"lon_v\", \"y\"] + RING_COLS + X_COLS\n",
        "        req = [c for c in req if c in run_full.columns]\n",
        "        r = run_full[req].dropna(how=\"any\")\n",
        "        if len(r) < 20:\n",
        "            continue\n",
        "        W = build_W_for_run(r)\n",
        "        if W is None:\n",
        "            continue\n",
        "        r = demean_by(r, FE_KEY, [\"y\"] + RING_COLS + [c for c in X_COLS if c in r.columns])\n",
        "        exog = [c for c in RING_COLS + X_COLS if c in r.columns and r[c].notna().all() and pd.api.types.is_numeric_dtype(r[c])]\n",
        "        if len(exog) < 2:\n",
        "            continue\n",
        "        X = np.asarray(r[exog], dtype=np.float64)\n",
        "        y = np.asarray(r[\"y\"], dtype=np.float64)\n",
        "        try:\n",
        "            model = spreg.GM_Error(y, X, w=W, name_x=exog)\n",
        "            resid = np.asarray(model.u).ravel()\n",
        "            y_pred = np.asarray(model.predy).ravel()\n",
        "\n",
        "            # Moran I on SEM residuals\n",
        "            mi = Moran(resid, W, permutations=999)\n",
        "\n",
        "            pr2 = getattr(model, \"pr2\", np.nan)\n",
        "            pr2_e = getattr(model, \"pr2_e\", np.nan)\n",
        "            sig2 = getattr(model, \"sig2\", np.nan)\n",
        "            lam = float(np.asarray(model.betas).flat[-1])\n",
        "\n",
        "            k = len(exog) + 1  # exog + lambda\n",
        "            n = len(y)\n",
        "\n",
        "            # Exposure label: \"ring\" since M7 uses ring terms not a single exposure\n",
        "            row = compute_gof(y, y_pred, \"M7_SEM\", sample, \"ring\", outcome,\n",
        "                              n_params=k,\n",
        "                              extra={\n",
        "                                  \"Moran_I_resid\": mi.I,\n",
        "                                  \"Moran_p_resid\": mi.p_sim,\n",
        "                                  \"pseudo_R2\": pr2,\n",
        "                                  \"pseudo_R2_e\": pr2_e,\n",
        "                                  \"lambda\": lam,\n",
        "                                  \"spreg_sig2\": sig2,\n",
        "                              })\n",
        "            gof_rows.append(row)\n",
        "        except Exception as e:\n",
        "            print(f\"  SEM skip: {sample}/{outcome} — {e}\")\n",
        "\n",
        "sem_gof = pd.DataFrame([r for r in gof_rows if r[\"model\"] == \"M7_SEM\"])\n",
        "if len(sem_gof) > 0:\n",
        "    print(sem_gof[[\"sample\", \"outcome\", \"N\", \"RMSE\", \"MAE\", \"R2\", \"pseudo_R2\", \"lambda\", \"Moran_I_resid\"]].to_string(index=False))\n",
        "else:\n",
        "    print(\"  (no SEM results)\")\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 5. Full comparison table\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FULL GOODNESS-OF-FIT COMPARISON TABLE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "gof_df = pd.DataFrame(gof_rows)\n",
        "\n",
        "# Core columns for display\n",
        "core_cols = [\"model\", \"sample\", \"exposure\", \"outcome\", \"N\", \"RMSE\", \"MAE\", \"R2\", \"sigma2\"]\n",
        "optional_cols = [\"adj_R2\", \"AIC\", \"BIC\", \"LogLik\", \"pseudo_R2\", \"rho\", \"lambda\",\n",
        "                 \"Moran_I_resid\", \"Moran_p_resid\", \"F_stat\"]\n",
        "display_cols = core_cols + [c for c in optional_cols if c in gof_df.columns]\n",
        "display_cols = [c for c in display_cols if c in gof_df.columns]\n",
        "\n",
        "print(gof_df[display_cols].to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "gof_df.to_csv(out_path(\"tables\", \"goodness_of_fit_all_models.csv\"), index=False)\n",
        "print(f\"\\nSaved: Output/tsls/tables/goodness_of_fit_all_models.csv  ({len(gof_df)} rows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eed622f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "RMSE by Model (lower is better)\n",
            "======================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'gof_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRMSE by Model (lower is better)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m rmse_pivot = \u001b[43mgof_df\u001b[49m.pivot_table(\n\u001b[32m     10\u001b[39m     index=[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     11\u001b[39m     columns=\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     values=\u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     aggfunc=\u001b[33m\"\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m ).round(\u001b[32m4\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(rmse_pivot.to_string())\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'gof_df' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Summary pivot tables & bar chart comparison\n",
        "# ============================================================\n",
        "\n",
        "# Ensure gof_df is available (load from CSV if not in memory after kernel restart)\n",
        "try:\n",
        "    gof_df\n",
        "except NameError:\n",
        "    _gof_csv = out_path(\"tables\", \"goodness_of_fit_all_models.csv\")\n",
        "    if os.path.exists(_gof_csv):\n",
        "        gof_df = pd.read_csv(_gof_csv)\n",
        "        print(\"(Loaded gof_df from CSV)\")\n",
        "    else:\n",
        "        raise NameError(\"gof_df not available and no CSV found. Run the GOF cell above first.\")\n",
        "\n",
        "# --- Pivot: RMSE by model × (sample, exposure, outcome) ---\n",
        "print(\"=\" * 70)\n",
        "print(\"RMSE by Model (lower is better)\")\n",
        "print(\"=\" * 70)\n",
        "rmse_pivot = gof_df.pivot_table(\n",
        "    index=[\"sample\", \"exposure\", \"outcome\"],\n",
        "    columns=\"model\",\n",
        "    values=\"RMSE\",\n",
        "    aggfunc=\"first\"\n",
        ").round(4)\n",
        "print(rmse_pivot.to_string())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"R² by Model (higher is better)\")\n",
        "print(\"=\" * 70)\n",
        "r2_pivot = gof_df.pivot_table(\n",
        "    index=[\"sample\", \"exposure\", \"outcome\"],\n",
        "    columns=\"model\",\n",
        "    values=\"R2\",\n",
        "    aggfunc=\"first\"\n",
        ").round(4)\n",
        "print(r2_pivot.to_string())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Moran I (residuals) by Model (closer to 0 → less residual spatial autocorrelation)\")\n",
        "print(\"=\" * 70)\n",
        "if \"Moran_I_resid\" in gof_df.columns:\n",
        "    moran_pivot = gof_df.pivot_table(\n",
        "        index=[\"sample\", \"exposure\", \"outcome\"],\n",
        "        columns=\"model\",\n",
        "        values=\"Moran_I_resid\",\n",
        "        aggfunc=\"first\"\n",
        "    ).round(4)\n",
        "    print(moran_pivot.to_string())\n",
        "\n",
        "# --- Bar chart: average RMSE per model ---\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Panel 1: Average RMSE\n",
        "avg_rmse = gof_df.groupby(\"model\")[\"RMSE\"].mean().sort_values()\n",
        "avg_rmse.plot.barh(ax=axes[0], color=[\"#2196F3\", \"#4CAF50\", \"#FF9800\", \"#F44336\"][:len(avg_rmse)])\n",
        "axes[0].set_title(\"Mean RMSE by Model (lower = better)\", fontsize=12)\n",
        "axes[0].set_xlabel(\"RMSE\")\n",
        "for i, (v, name) in enumerate(zip(avg_rmse.values, avg_rmse.index)):\n",
        "    axes[0].text(v + 0.001, i, f\"{v:.4f}\", va=\"center\", fontsize=9)\n",
        "\n",
        "# Panel 2: Average R²\n",
        "avg_r2 = gof_df.groupby(\"model\")[\"R2\"].mean().sort_values(ascending=False)\n",
        "avg_r2.plot.barh(ax=axes[1], color=[\"#2196F3\", \"#4CAF50\", \"#FF9800\", \"#F44336\"][:len(avg_r2)])\n",
        "axes[1].set_title(\"Mean R² by Model (higher = better)\", fontsize=12)\n",
        "axes[1].set_xlabel(\"R²\")\n",
        "for i, (v, name) in enumerate(zip(avg_r2.values, avg_r2.index)):\n",
        "    axes[1].text(v + 0.001, i, f\"{v:.4f}\", va=\"center\", fontsize=9)\n",
        "\n",
        "# Panel 3: Average Moran I (residuals)\n",
        "if \"Moran_I_resid\" in gof_df.columns:\n",
        "    avg_moran = gof_df.groupby(\"model\")[\"Moran_I_resid\"].mean().sort_values()\n",
        "    avg_moran.plot.barh(ax=axes[2], color=[\"#2196F3\", \"#4CAF50\", \"#FF9800\", \"#F44336\"][:len(avg_moran)])\n",
        "    axes[2].set_title(\"Mean Moran I (resid) by Model\\n(closer to 0 = less spatial autocorrelation)\", fontsize=11)\n",
        "    axes[2].set_xlabel(\"Moran I\")\n",
        "    for i, (v, name) in enumerate(zip(avg_moran.values, avg_moran.index)):\n",
        "        axes[2].text(v + 0.001, i, f\"{v:.4f}\", va=\"center\", fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(out_path(\"figures\", \"gof_comparison_barplot.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"\\nSaved: Output/tsls/figures/gof_comparison_barplot.png\")\n",
        "\n",
        "# --- Detailed per-run comparison plot: RMSE across all runs ---\n",
        "fig, ax = plt.subplots(figsize=(14, max(6, len(gof_df) * 0.25)))\n",
        "models_ordered = [\"Baseline_IV2SLS\", \"M5_SLX\", \"M6_SDM\", \"M7_SEM\"]\n",
        "colors = {\"Baseline_IV2SLS\": \"#9E9E9E\", \"M5_SLX\": \"#2196F3\", \"M6_SDM\": \"#4CAF50\", \"M7_SEM\": \"#FF9800\"}\n",
        "gof_df[\"run_label\"] = gof_df[\"sample\"] + \" | \" + gof_df[\"exposure\"] + \" | \" + gof_df[\"outcome\"]\n",
        "for m in models_ordered:\n",
        "    sub = gof_df[gof_df[\"model\"] == m].sort_values(\"run_label\")\n",
        "    if len(sub) > 0:\n",
        "        ax.barh(sub[\"run_label\"] + f\"  ({m})\", sub[\"RMSE\"], label=m,\n",
        "                color=colors.get(m, \"#607D8B\"), alpha=0.85, height=0.7)\n",
        "ax.set_xlabel(\"RMSE\", fontsize=12)\n",
        "ax.set_title(\"RMSE per Model × Run\", fontsize=13)\n",
        "ax.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(out_path(\"figures\", \"gof_rmse_per_run.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Saved: Output/tsls/figures/gof_rmse_per_run.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b24e1af",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fbd488",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "playgroundenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
